{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/alexander/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=m, std=s),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "print(torch.round(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1pack.utils.data import SegmentationDataset\n",
    "\n",
    "#pip install -e .\n",
    "#pip install  abbyy_course_cvdl_t2\n",
    "\n",
    "from pathlib import Path\n",
    "from course_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "\n",
    "from task1pack.utils.data import HeatmapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, course_ocr_t1.data.MidvPackage)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = Path() / '..' / '..' / 'midv500_compressed'\n",
    "#DATASET_PATH = Path() / '..' / '..' / '..' / '..' / '..' / '..' / 'Downloads' / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "\n",
    "# Собираем список пакетов (MidvPackage) \n",
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10750 4250\n",
      "torch.Size([3, 416, 416]) torch.Size([1, 416, 416])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "\n",
    "IMAGE_SIZE = [416, 416]\n",
    "HEATMAP_SIZE = [104, 104]\n",
    "\n",
    "image_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(IMAGE_SIZE),\n",
    "])\n",
    "\n",
    "target_transforms = Compose([\n",
    "    Resize(IMAGE_SIZE),\n",
    "])\n",
    "\n",
    "train_dataset = SegmentationDataset(data_packs=data_packs, \n",
    "        split='train', image_transforms=image_transforms, target_transforms=target_transforms)\n",
    "test_dataset = SegmentationDataset(data_packs=data_packs, \n",
    "        split='test', image_transforms=image_transforms, target_transforms=target_transforms)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[0][0].shape, train_dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1pack.utils.train import train_model, show_train_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_config = {\n",
    "    'batch_size': 24,\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 100,\n",
    "    'step_size': 15,\n",
    "    'gamma': 0.1,\n",
    "}\n",
    "\n",
    "device = 'cpu'\n",
    "criterion = BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, test_losses, trained_model \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      2\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtrain_dataset, \n\u001b[1;32m      3\u001b[0m     test_dataset\u001b[39m=\u001b[39;49mtest_dataset, \n\u001b[1;32m      4\u001b[0m     model\u001b[39m=\u001b[39;49mmodel, \n\u001b[1;32m      5\u001b[0m     train_dataloader_kwargs\u001b[39m=\u001b[39;49mtrain_dataloader_config, \n\u001b[1;32m      6\u001b[0m     test_dataloader_kwargs\u001b[39m=\u001b[39;49mtest_dataloader_config, \n\u001b[1;32m      7\u001b[0m     training_kwargs\u001b[39m=\u001b[39;49mtraining_config,\n\u001b[1;32m      8\u001b[0m     criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m      9\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     10\u001b[0m     wandb_instance\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/computerScience/phystech/10sem/docProcessing/course_ocr/task1/task1pack/utils/train.py:116\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, test_dataset, model, criterion, device, train_dataloader_kwargs, test_dataloader_kwargs, training_kwargs, wandb_instance)\u001b[0m\n\u001b[1;32m    113\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(train_dataset, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_dataloader_kwargs)\n\u001b[1;32m    114\u001b[0m test_dataloader \u001b[39m=\u001b[39m DataLoader(test_dataset, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtest_dataloader_kwargs)\n\u001b[0;32m--> 116\u001b[0m train_loss, test_loss \u001b[39m=\u001b[39m train_epochs(model, train_dataloader, test_dataloader, training_kwargs, criterion, device, wandb_instance\u001b[39m=\u001b[39;49mwandb_instance)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(train_loss), np\u001b[39m.\u001b[39marray(test_loss), model\n",
      "File \u001b[0;32m~/computerScience/phystech/10sem/docProcessing/course_ocr/task1/task1pack/utils/train.py:64\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(model, train_loader, test_loader, train_args, criterion, device, wandb_instance)\u001b[0m\n\u001b[1;32m     61\u001b[0m scheduler \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mtrain_args[\u001b[39m'\u001b[39m\u001b[39mstep_size\u001b[39m\u001b[39m'\u001b[39m], gamma\u001b[39m=\u001b[39mtrain_args[\u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     63\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 64\u001b[0m test_losses \u001b[39m=\u001b[39m [eval_loss(model, test_loader, criterion, device)]\n\u001b[1;32m     66\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minitial loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(test_losses[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m wandb_instance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/computerScience/phystech/10sem/docProcessing/course_ocr/task1/task1pack/utils/train.py:51\u001b[0m, in \u001b[0;36meval_loss\u001b[0;34m(model, data_loader, criterion, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m x, target \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     50\u001b[0m     x, target \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 51\u001b[0m     prediction \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     52\u001b[0m     loss \u001b[39m=\u001b[39m criterion(prediction, target)\n\u001b[1;32m     53\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master/unet.py:61\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m dec2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupconv2(dec3)\n\u001b[1;32m     60\u001b[0m dec2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((dec2, enc2), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m dec2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder2(dec2)\n\u001b[1;32m     62\u001b[0m dec1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupconv1(dec2)\n\u001b[1;32m     63\u001b[0m dec1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((dec1, enc1), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, trained_model = train_model(\n",
    "    train_dataset=train_dataset, \n",
    "    test_dataset=test_dataset, \n",
    "    model=model, \n",
    "    train_dataloader_kwargs=train_dataloader_config, \n",
    "    test_dataloader_kwargs=test_dataloader_config, \n",
    "    training_kwargs=training_config,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    wandb_instance=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
