{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy9sem/course_cvdl/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/avashchilko/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1pack.utils.data import SegmentationDataset\n",
    "\n",
    "#pip install -e .\n",
    "#pip install  abbyy_course_cvdl_t2\n",
    "\n",
    "from pathlib import Path\n",
    "from course_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "\n",
    "from task1pack.utils.data import HeatmapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, course_ocr_t1.data.MidvPackage)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATASET_PATH = Path() / '..' / '..' / 'midv500_compressed'\n",
    "DATASET_PATH = Path() / '..' / '..' / 'data' / 'midv500_compressed'\n",
    "#DATASET_PATH = Path() / '..' / '..' / '..' / '..' / '..' / '..' / 'Downloads' / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "\n",
    "# Собираем список пакетов (MidvPackage) \n",
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10750 4250\n",
      "torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "\n",
    "IMAGE_SIZE = [512, 512]\n",
    "\n",
    "image_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(IMAGE_SIZE),\n",
    "])\n",
    "\n",
    "target_transforms = Compose([\n",
    "    Resize(IMAGE_SIZE),\n",
    "])\n",
    "\n",
    "train_dataset = SegmentationDataset(data_packs=data_packs, \n",
    "        split='train', image_transforms=image_transforms, target_transforms=target_transforms)\n",
    "test_dataset = SegmentationDataset(data_packs=data_packs, \n",
    "        split='test', image_transforms=image_transforms, target_transforms=target_transforms)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[0][0].shape, train_dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1pack.utils.train import train_model, show_train_plots, train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvashchilkoav\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/avashchilko/abbyy10sem/course_ocr/task1/wandb/run-20230329_095419-bvajuad1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/bvajuad1' target=\"_blank\">torch unet 100 epochs with lr=0.001 new train</a></strong> to <a href='https://wandb.ai/vashchilkoav/ocr%20task%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vashchilkoav/ocr%20task%201' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%201</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/bvajuad1' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%201/runs/bvajuad1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/bvajuad1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0014f7da00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'torch unet'\n",
    "\n",
    "train_dataloader_config = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 100,\n",
    "    'step_size': 25,\n",
    "    'milestones': [25, 50, 75],\n",
    "    'gamma': 0.7,\n",
    "}\n",
    "\n",
    "\n",
    "device = 'cuda:1'\n",
    "criterion = BCELoss()\n",
    "\n",
    "wandb.init(\n",
    "    project='ocr task 1',\n",
    "    name='{} {} epochs with lr={} new train'.format(model_name, training_config['epochs'], training_config['lr']),\n",
    "    config={\n",
    "        'train_dataloader_config': train_dataloader_config,\n",
    "        'test_dataloader_config': test_dataloader_config,\n",
    "        'training_config': training_config,\n",
    "\n",
    "    \"architecture\": model_name,\n",
    "    \"dataset\": \"MIDV-500\",\n",
    "    \"criterion\": \"BCELoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"image_size\": IMAGE_SIZE,  \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Epoch 2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, test_losses, trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/abbyy10sem/course_ocr/task1/task1pack/utils/train.py:326\u001b[0m, in \u001b[0;36mtrain_new\u001b[0;34m(model, criterion, device, train_dataset, test_dataset, train_dataloader_kwargs, test_dataloader_kwargs, training_kwargs, wandb_instance, eval_every)\u001b[0m\n\u001b[1;32m    324\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, target \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28minput\u001b[39m, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    327\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    328\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, trained_model = train_new(\n",
    "    train_dataset=train_dataset, \n",
    "    test_dataset=test_dataset, \n",
    "    model=model, \n",
    "    train_dataloader_kwargs=train_dataloader_config, \n",
    "    test_dataloader_kwargs=test_dataloader_config, \n",
    "    training_kwargs=training_config,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    wandb_instance=wandb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), './unet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvashchilkoav\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/avashchilko/abbyy10sem/course_ocr/task1/wandb/run-20230329_092121-qrcqdj8e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e' target=\"_blank\">torch unet 100 epochs with lr=0.001 old train</a></strong> to <a href='https://wandb.ai/vashchilkoav/ocr%20task%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vashchilkoav/ocr%20task%201' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%201</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2089974b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'torch unet'\n",
    "\n",
    "train_dataloader_config = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': False,\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 100,\n",
    "    'step_size': 25,\n",
    "    'gamma': 0.7,\n",
    "}\n",
    "\n",
    "\n",
    "device = 'cuda:1'\n",
    "criterion = BCELoss()\n",
    "\n",
    "wandb.init(\n",
    "    project='ocr task 1',\n",
    "    name='{} {} epochs with lr={} old train'.format(model_name, training_config['epochs'], training_config['lr']),\n",
    "    config={\n",
    "        'train_dataloader_config': train_dataloader_config,\n",
    "        'test_dataloader_config': test_dataloader_config,\n",
    "        'training_config': training_config,\n",
    "\n",
    "    \"architecture\": model_name,\n",
    "    \"dataset\": \"MIDV-500\",\n",
    "    \"criterion\": \"BCELoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"image_size\": IMAGE_SIZE,  \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1pack.utils.train import train_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0|0; total loss:0.024599019438028336\n",
      "last losse: 3.3208677768707275\n",
      "epoch 0|135; total loss:0.26201707124710083\n",
      "last losse: 0.203396275639534\n",
      "epoch 0|270; total loss:0.10895795375108719\n",
      "last losse: 0.06776674091815948\n",
      "epoch 0|405; total loss:0.07589032500982285\n",
      "last losse: 0.12207520008087158\n",
      "epoch 0|540; total loss:0.06147361174225807\n",
      "last losse: 0.08387358486652374\n",
      "epoch 0|675; total loss:0.04958047345280647\n",
      "last losse: 0.06973102688789368\n",
      "epoch 0|810; total loss:0.04651539400219917\n",
      "last losse: 0.08303708583116531\n",
      "epoch 0|945; total loss:0.039703369140625\n",
      "last losse: 0.022554796189069748\n",
      "epoch 0|1080; total loss:0.0352974496781826\n",
      "last losse: 0.013174505904316902\n",
      "epoch 0|1215; total loss:0.0334409661591053\n",
      "last losse: 0.014591091312468052\n",
      "epoch 1|0; total loss:0.00013088210835121572\n",
      "last losse: 0.017669085413217545\n",
      "epoch 1|135; total loss:0.026703229174017906\n",
      "last losse: 0.014996595680713654\n",
      "epoch 1|270; total loss:0.027345990762114525\n",
      "last losse: 0.018553050234913826\n",
      "epoch 1|405; total loss:0.01732623390853405\n",
      "last losse: 0.0056339772418141365\n",
      "epoch 1|540; total loss:0.022637590765953064\n",
      "last losse: 0.009889529086649418\n",
      "epoch 1|675; total loss:0.02342686802148819\n",
      "last losse: 0.0385466068983078\n",
      "epoch 1|810; total loss:0.0169496089220047\n",
      "last losse: 0.009482031688094139\n",
      "epoch 1|945; total loss:0.03201574087142944\n",
      "last losse: 0.03338208422064781\n",
      "epoch 1|1080; total loss:0.020355509594082832\n",
      "last losse: 0.011579606682062149\n",
      "epoch 1|1215; total loss:0.020450005307793617\n",
      "last losse: 0.007700333371758461\n",
      "epoch 2|0; total loss:7.46212390367873e-05\n",
      "last losse: 0.010073867626488209\n",
      "epoch 2|135; total loss:0.014578484930098057\n",
      "last losse: 0.007137346547096968\n",
      "epoch 2|270; total loss:0.013476002030074596\n",
      "last losse: 0.007217948324978352\n",
      "epoch 2|405; total loss:0.019076436758041382\n",
      "last losse: 0.015187092125415802\n",
      "epoch 2|540; total loss:0.022724179551005363\n",
      "last losse: 0.017562055960297585\n",
      "epoch 2|675; total loss:0.01877673715353012\n",
      "last losse: 0.013894748874008656\n",
      "epoch 2|810; total loss:0.015833359211683273\n",
      "last losse: 0.009143737144768238\n",
      "epoch 2|945; total loss:0.017988070845603943\n",
      "last losse: 0.011178427375853062\n",
      "epoch 2|1080; total loss:0.014752735383808613\n",
      "last losse: 0.014057690277695656\n",
      "epoch 2|1215; total loss:0.018415454775094986\n",
      "last losse: 0.008011922240257263\n",
      "epoch 3|0; total loss:9.124776988755912e-05\n",
      "last losse: 0.012318449094891548\n",
      "epoch 3|135; total loss:0.013375524431467056\n",
      "last losse: 0.01564442180097103\n",
      "epoch 3|270; total loss:0.013423295691609383\n",
      "last losse: 0.014722619205713272\n",
      "epoch 3|405; total loss:0.009715178981423378\n",
      "last losse: 0.005307832732796669\n",
      "epoch 3|540; total loss:0.010918700136244297\n",
      "last losse: 0.008267908357083797\n",
      "epoch 3|675; total loss:0.011182446032762527\n",
      "last losse: 0.011335741728544235\n",
      "epoch 3|810; total loss:0.017131004482507706\n",
      "last losse: 0.012569161131978035\n",
      "epoch 3|945; total loss:0.014416078105568886\n",
      "last losse: 0.009924632497131824\n",
      "epoch 3|1080; total loss:0.015594583004713058\n",
      "last losse: 0.018054094165563583\n",
      "epoch 3|1215; total loss:0.020470917224884033\n",
      "last losse: 0.007937767542898655\n",
      "epoch 4|0; total loss:0.00013783504255115986\n",
      "last losse: 0.0186077319085598\n",
      "epoch 4|135; total loss:0.011633236892521381\n",
      "last losse: 0.01026180200278759\n",
      "epoch 4|270; total loss:0.012065775692462921\n",
      "last losse: 0.010591643862426281\n",
      "epoch 4|405; total loss:0.008936949074268341\n",
      "last losse: 0.006399882957339287\n",
      "epoch 4|540; total loss:0.010437616147100925\n",
      "last losse: 0.008882499299943447\n",
      "epoch 4|675; total loss:0.01639028824865818\n",
      "last losse: 0.00821767095476389\n",
      "epoch 4|810; total loss:0.011585474945604801\n",
      "last losse: 0.0068232472985982895\n",
      "epoch 4|945; total loss:0.012890849262475967\n",
      "last losse: 0.01414138451218605\n",
      "epoch 4|1080; total loss:0.010168670676648617\n",
      "last losse: 0.005307796411216259\n",
      "epoch 4|1215; total loss:0.010078887455165386\n",
      "last losse: 0.007659146562218666\n",
      "epoch 5|0; total loss:5.649777449434623e-05\n",
      "last losse: 0.007627199869602919\n",
      "epoch 5|135; total loss:0.008158250711858273\n",
      "last losse: 0.006987134926021099\n",
      "epoch 5|270; total loss:0.012899036519229412\n",
      "last losse: 0.009394926950335503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_old\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/abbyy10sem/course_ocr/task1/task1pack/utils/train.py:158\u001b[0m, in \u001b[0;36mtrain_old\u001b[0;34m(dataset, net, criterion, batch_size, lr, epochs, device, wandb_instance)\u001b[0m\n\u001b[1;32m    156\u001b[0m inputs, anno \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     anno \u001b[38;5;241m=\u001b[39m anno\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    160\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_old(\n",
    "    train_dataset, \n",
    "    net=model, \n",
    "    criterion=criterion, \n",
    "    batch_size=train_dataloader_config['batch_size'], \n",
    "    epochs=training_config['epochs'],\n",
    "    lr=training_config['lr'], \n",
    "    device=device,\n",
    "    wandb_instance=wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">torch unet 100 epochs with lr=0.001 old train</strong> at: <a href='https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%201/runs/qrcqdj8e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230329_092121-qrcqdj8e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), './unet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
