{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, LMDBReader\n",
    "\n",
    "# your path to data\n",
    "train_path = r'/DATA/ichuviliaeva/ocr_data/train.lmdb'\n",
    "test_path = r'/DATA/ichuviliaeva/ocr_data/test.lmdb'\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy9sem/course_cvdl/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = LMDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3b277a0370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task2pack.utils.train import show_train_plots, train_with_trainable_loss\n",
    "from task2pack.utils.data import HWDBDataset \n",
    "\n",
    "from task2pack.models.resnet import ResNet18GrayscaleFeatPytorch\n",
    "from task2pack.models.loss import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = ResNet34GrayscaleFeat(train_helper.vocabulary.num_classes())\n",
    "\"\"\"\n",
    "model = ResNet18GrayscaleFeatPytorch(train_helper.vocabulary.num_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvashchilkoav\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/avashchilko/abbyy10sem/course_ocr/task2/wandb/run-20230410_074926-xjab8tmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/xjab8tmx' target=\"_blank\">ResNet18GrayscaleFeatPytorch 30 epochs with lr=0.001 no augment</a></strong> to <a href='https://wandb.ai/vashchilkoav/ocr%20task%202' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vashchilkoav/ocr%20task%202' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%202</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/xjab8tmx' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%202/runs/xjab8tmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/xjab8tmx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3714fd5d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ResNet18GrayscaleFeatPytorch'\n",
    "\n",
    "train_transfroms = nn.Sequential(\n",
    "    transforms.Resize((128, 128))\n",
    ")\n",
    "\n",
    "val_transfroms = nn.Sequential(\n",
    "    transforms.Resize((128, 128))\n",
    ")\n",
    "\n",
    "train_dataloader_config = {\n",
    "    'batch_size': 512,\n",
    "    'shuffle': True,\n",
    "    'drop_last': True,\n",
    "    'num_workers': 8,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 2048,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 8,\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 30,\n",
    "    'milestones': [30, 50, 75],\n",
    "    'gamma': 0.7,\n",
    "    'weight_criterion': 0.5,\n",
    "    'lr_criterion': 0.5,\n",
    "}\n",
    "\n",
    "device = 'cuda:2'\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "centerloss = CenterLoss(num_classes=train_helper.vocabulary.num_classes(), feat_dim=512)\n",
    "\n",
    "wandb.init(\n",
    "    project='ocr task 2',\n",
    "    name='{} {} epochs with lr={} no augment'.format(model_name, training_config['epochs'], training_config['lr']),\n",
    "    config={\n",
    "        'train_dataloader_config': train_dataloader_config,\n",
    "        'test_dataloader_config': test_dataloader_config,\n",
    "        'training_config': training_config,\n",
    "        'train_transforms': train_transfroms,\n",
    "        'val_transforms': val_transfroms,\n",
    "\n",
    "        \"architecture\": model_name,\n",
    "        \"dataset\": \"CASIA Offline Chinese Handwriting\",\n",
    "        \"criterion\": \"Cross Entropy Loss + Centerloss\",\n",
    "        \"optimizer\": \"Adam + SGD(Centerloss)\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HWDBDataset(train_helper, transforms=train_transfroms)\n",
    "val_dataset = HWDBDataset(val_helper, transforms=val_transfroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy10sem/course_ocr/task2/task2pack/models/loss.py:30: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val: [regular_loss: 0.004380668100760496, trainable_loss: 0.17494468240214525, accuracy: 0.00017995404966421506]\n",
      "Epoch 1:\n",
      "Train loss: [regular: 0.00905557293790458 trainable: 0.2479257845361131]\n",
      "Epoch 2:\n",
      "Train loss: [regular: 0.0006330361488530667 trainable: 0.05119721642063917]\n",
      "Val : [regular_loss: 0.00014152760570191895, trainable_loss: 0.006848004816510555, accuracy: 0.9337753583955545]\n",
      "Epoch 3:\n",
      "Train loss: [regular: 0.00045196787584120225 trainable: 0.017866380896539785]\n",
      "Epoch 4:\n",
      "Train loss: [regular: 0.0003753486430669243 trainable: 0.008613275485200567]\n",
      "Val : [regular_loss: 0.00013124182537349965, trainable_loss: 0.0017255141189233215, accuracy: 0.938126833475797]\n",
      "Epoch 5:\n",
      "Train loss: [regular: 0.0003262252724020917 trainable: 0.004892828965876938]\n",
      "Epoch 6:\n",
      "Train loss: [regular: 0.0002893358214206503 trainable: 0.0031159088038424446]\n",
      "Val : [regular_loss: 0.00010688891287610671, trainable_loss: 0.0007183044750920527, accuracy: 0.949484105868829]\n",
      "Epoch 7:\n",
      "Train loss: [regular: 0.00025996755379514223 trainable: 0.0021766046675264915]\n",
      "Epoch 8:\n",
      "Train loss: [regular: 0.00023579534676496778 trainable: 0.0016430988467066852]\n",
      "Val : [regular_loss: 0.00010708035820000501, trainable_loss: 0.00045288293638016166, accuracy: 0.9505762407909291]\n",
      "Epoch 9:\n",
      "Train loss: [regular: 0.00021533539813939863 trainable: 0.0013132346778192386]\n",
      "Epoch 10:\n",
      "Train loss: [regular: 0.000197888150347609 trainable: 0.0010939339951968668]\n",
      "Val : [regular_loss: 0.00010872001504692944, trainable_loss: 0.0003427151141193443, accuracy: 0.9502551158919593]\n",
      "Epoch 11:\n",
      "Train loss: [regular: 0.00018215298825725916 trainable: 0.0009356277965955136]\n",
      "Epoch 12:\n",
      "Train loss: [regular: 0.00016962774162458165 trainable: 0.0008207275644874115]\n",
      "Val : [regular_loss: 0.00010644225449393998, trainable_loss: 0.00027939402077084476, accuracy: 0.952580556585465]\n",
      "Epoch 13:\n",
      "Train loss: [regular: 0.00015735912857202231 trainable: 0.0007265508342260538]\n",
      "Epoch 14:\n",
      "Train loss: [regular: 0.00014655484037291703 trainable: 0.0006501916901171283]\n",
      "Val : [regular_loss: 0.00010246161525790065, trainable_loss: 0.00023647048221039663, accuracy: 0.9551433504651657]\n",
      "Epoch 15:\n",
      "Train loss: [regular: 0.00013745034343791676 trainable: 0.0005894170532831633]\n",
      "Epoch 16:\n",
      "Train loss: [regular: 0.0001286436512296254 trainable: 0.0005350481074941853]\n",
      "Val : [regular_loss: 0.00010604866708388844, trainable_loss: 0.00021070126530089265, accuracy: 0.9547353511973925]\n",
      "Epoch 17:\n",
      "Train loss: [regular: 0.00012081406591206855 trainable: 0.0004921347590520373]\n",
      "Epoch 18:\n",
      "Train loss: [regular: 0.00011353857952522006 trainable: 0.00045342873019136177]\n",
      "Val : [regular_loss: 0.00012084311244107205, trainable_loss: 0.0002035973721384036, accuracy: 0.9483019939218968]\n",
      "Epoch 19:\n",
      "Train loss: [regular: 0.00010723899248861877 trainable: 0.00041955529847650523]\n",
      "Epoch 20:\n",
      "Train loss: [regular: 0.00010211329325884126 trainable: 0.0003926001509831589]\n",
      "Val : [regular_loss: 0.00010864457542323879, trainable_loss: 0.00017258122985078052, accuracy: 0.9555591063730107]\n",
      "Epoch 21:\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, train_centerloss, test_centerloss, trained_model = train_with_trainable_loss(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=val_dataset,\n",
    "    model=model, \n",
    "    criterion=criterion,\n",
    "    trainable_criterion=centerloss,\n",
    "    train_dataloader_kwargs=train_dataloader_config,\n",
    "    test_dataloader_kwargs=test_dataloader_config,\n",
    "    training_kwargs=training_config,\n",
    "    device=device,\n",
    "    wandb_instance=wandb,\n",
    "    eval_every=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_plots(train_losses, test_losses, 'ResNet34Grayscale CrossEntropy')\n",
    "show_train_plots(train_centerloss, test_centerloss, 'ResNet34Grayscale Centerloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_ocr_t2.evaluate import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_path = r'/DATA/ichuviliaeva/ocr_data/test.lmdb'\n",
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = LMDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')\n",
    "\n",
    "test_transforms = nn.Sequential(\n",
    "    transforms.Resize((128, 128)),\n",
    ")\n",
    "\n",
    "test_dataset = HWDBDataset(test_helper, transforms=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=8)\n",
    "\n",
    "preds = []\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        logits, _ = trained_model(X.to(torch.float32).to(device))\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)\n",
    "    \n",
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)\n",
    "        \n",
    "test_accuracy = evaluate('./gt.txt', './pred.txt')\n",
    "wandb.run.summary['test_accuracy'] = test_accuracy\n",
    "wandb.run.summary['test_transforms'] = test_transforms\n",
    "\n",
    "torch.save(trained_model.state_dict(), './model.pth')\n",
    "wandb.save('./model.pth')\n",
    "wandb.save('./pred.txt')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
