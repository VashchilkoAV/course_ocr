{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, LMDBReader\n",
    "\n",
    "# your path to data\n",
    "train_path = r'/DATA/ichuviliaeva/ocr_data/train.lmdb'\n",
    "test_path = r'/DATA/ichuviliaeva/ocr_data/test.lmdb'\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy9sem/course_cvdl/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = LMDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb06602f370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task2pack.utils.train import show_train_plots, train_with_trainable_loss\n",
    "from task2pack.utils.data import HWDBDataset \n",
    "\n",
    "from task2pack.models.resnet import ResNet12GrayscaleFeatPytorch\n",
    "from task2pack.models.loss import CenterLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = ResNet34GrayscaleFeat(train_helper.vocabulary.num_classes())\n",
    "\"\"\"\n",
    "model = ResNet12GrayscaleFeatPytorch(train_helper.vocabulary.num_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvashchilkoav\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/avashchilko/abbyy10sem/course_ocr/task2/wandb/run-20230409_144138-opjxdp34</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/opjxdp34' target=\"_blank\">ResNet12GrayscaleFeatPytorch 40 epochs with lr=0.001 no augment</a></strong> to <a href='https://wandb.ai/vashchilkoav/ocr%20task%202' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vashchilkoav/ocr%20task%202' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%202</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/opjxdp34' target=\"_blank\">https://wandb.ai/vashchilkoav/ocr%20task%202/runs/opjxdp34</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vashchilkoav/ocr%20task%202/runs/opjxdp34?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fac537fda90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ResNet12GrayscaleFeatPytorch'\n",
    "\n",
    "train_transfroms = nn.Sequential(\n",
    "    transforms.Resize((128, 128))\n",
    ")\n",
    "\n",
    "val_transfroms = nn.Sequential(\n",
    "    transforms.Resize((128, 128))\n",
    ")\n",
    "\n",
    "train_dataloader_config = {\n",
    "    'batch_size': 512,\n",
    "    'shuffle': True,\n",
    "    'drop_last': True,\n",
    "    'num_workers': 8,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 2048,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 8,\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 40,\n",
    "    'milestones': [40, 50, 75],\n",
    "    'gamma': 0.7,\n",
    "    'weight_criterion': 0.3,\n",
    "    'lr_criterion': 0.5,\n",
    "}\n",
    "\n",
    "device = 'cuda:2'\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "centerloss = CenterLoss(num_classes=train_helper.vocabulary.num_classes(), feat_dim=512)\n",
    "\n",
    "wandb.init(\n",
    "    project='ocr task 2',\n",
    "    name='{} {} epochs with lr={} no augment'.format(model_name, training_config['epochs'], training_config['lr']),\n",
    "    config={\n",
    "        'train_dataloader_config': train_dataloader_config,\n",
    "        'test_dataloader_config': test_dataloader_config,\n",
    "        'training_config': training_config,\n",
    "        'train_transforms': train_transfroms,\n",
    "        'val_transforms': val_transfroms,\n",
    "\n",
    "        \"architecture\": model_name,\n",
    "        \"dataset\": \"CASIA Offline Chinese Handwriting\",\n",
    "        \"criterion\": \"Cross Entropy Loss + Centerloss\",\n",
    "        \"optimizer\": \"Adam + SGD(Centerloss)\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HWDBDataset(train_helper, transforms=train_transfroms)\n",
    "val_dataset = HWDBDataset(val_helper, transforms=val_transfroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy10sem/course_ocr/task2/task2pack/models/loss.py:30: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val: [regular_loss: 0.004350887003099979, trainable_loss: 0.0767397590527928, accuracy: 5.7399136530827216e-05]\n",
      "Epoch 1:\n",
      "Train loss: [regular: 0.00746226896521204 trainable: 0.15184186068554675]\n",
      "Epoch 2:\n",
      "Train loss: [regular: 0.0007994218671546974 trainable: 0.03814035727705972]\n",
      "Val : [regular_loss: 0.00023147866785392293, trainable_loss: 0.005389864329863562, accuracy: 0.8907337626375058]\n",
      "Epoch 3:\n",
      "Train loss: [regular: 0.000551695716671635 trainable: 0.013713069831213493]\n",
      "Epoch 4:\n",
      "Train loss: [regular: 0.00046165847345572644 trainable: 0.006213338089851933]\n",
      "Val : [regular_loss: 0.00015091135317931196, trainable_loss: 0.0011335323260755431, accuracy: 0.9229501915114434]\n",
      "Epoch 5:\n",
      "Train loss: [regular: 0.00040214950120102505 trainable: 0.0032547932806320052]\n",
      "Epoch 6:\n",
      "Train loss: [regular: 0.00035551926593102795 trainable: 0.0018976553016466107]\n",
      "Val : [regular_loss: 0.00012135864119783903, trainable_loss: 0.00038819672168297504, accuracy: 0.9366918550625263]\n",
      "Epoch 7:\n",
      "Train loss: [regular: 0.0003175414786965588 trainable: 0.0012150608484742399]\n",
      "Epoch 8:\n",
      "Train loss: [regular: 0.0002851789703639912 trainable: 0.0008443937019403132]\n",
      "Val : [regular_loss: 0.00010858014900478722, trainable_loss: 0.0001897177021663774, accuracy: 0.9430166193770178]\n",
      "Epoch 9:\n",
      "Train loss: [regular: 0.00025825950291187317 trainable: 0.0006285754041715438]\n",
      "Epoch 10:\n",
      "Train loss: [regular: 0.0002341117466562613 trainable: 0.0004934496770109827]\n",
      "Val : [regular_loss: 0.00010260547506062458, trainable_loss: 0.00011774390910608279, accuracy: 0.9455468353684171]\n",
      "Epoch 11:\n",
      "Train loss: [regular: 0.00021411515106685284 trainable: 0.00040365247768608833]\n",
      "Epoch 12:\n",
      "Train loss: [regular: 0.00019601803046669685 trainable: 0.00034004745719125963]\n",
      "Val : [regular_loss: 9.818461714614524e-05, trainable_loss: 8.496221226687879e-05, accuracy: 0.9472719121203707]\n",
      "Epoch 13:\n",
      "Train loss: [regular: 0.00017976832652185482 trainable: 0.0002933622410590704]\n",
      "Epoch 14:\n",
      "Train loss: [regular: 0.0001652899563978312 trainable: 0.00025759273244834683]\n",
      "Val : [regular_loss: 0.0001001053174583205, trainable_loss: 6.693242922037813e-05, accuracy: 0.9462806135192031]\n",
      "Epoch 15:\n",
      "Train loss: [regular: 0.00015236979361281402 trainable: 0.00022945279760644272]\n",
      "Epoch 16:\n",
      "Train loss: [regular: 0.00014017515882049216 trainable: 0.00020673720613012962]\n",
      "Val : [regular_loss: 9.041104738631706e-05, trainable_loss: 5.336855643593832e-05, accuracy: 0.9513922393264754]\n",
      "Epoch 17:\n",
      "Train loss: [regular: 0.00012959365118633316 trainable: 0.00018818569873482301]\n",
      "Epoch 18:\n",
      "Train loss: [regular: 0.00011967181611591821 trainable: 0.0001727484276579234]\n",
      "Val : [regular_loss: 8.9875460018694e-05, trainable_loss: 4.529643671764064e-05, accuracy: 0.9517692120339617]\n",
      "Epoch 19:\n",
      "Train loss: [regular: 0.00011057370413140303 trainable: 0.00015967528121235493]\n",
      "Epoch 20:\n",
      "Train loss: [regular: 0.0001024273146082353 trainable: 0.00014857711526606042]\n",
      "Val : [regular_loss: 9.050113670894853e-05, trainable_loss: 3.9540019098497575e-05, accuracy: 0.9513022623016433]\n",
      "Epoch 21:\n",
      "Train loss: [regular: 9.519045710191181e-05 trainable: 0.00013897210267060667]\n",
      "Epoch 22:\n",
      "Train loss: [regular: 8.787187307775915e-05 trainable: 0.00013035811199464963]\n",
      "Val : [regular_loss: 9.135583903789154e-05, trainable_loss: 3.49227209663102e-05, accuracy: 0.9514636004151353]\n",
      "Epoch 23:\n",
      "Train loss: [regular: 8.184044889321312e-05 trainable: 0.00012314073007018233]\n",
      "Epoch 24:\n",
      "Train loss: [regular: 7.649217925128147e-05 trainable: 0.00011646549647310223]\n",
      "Val : [regular_loss: 8.97009486594594e-05, trainable_loss: 3.1382026592716465e-05, accuracy: 0.9521291201332901]\n",
      "Epoch 25:\n",
      "Train loss: [regular: 7.068458376757224e-05 trainable: 0.000110411884988256]\n",
      "Epoch 26:\n",
      "Train loss: [regular: 6.62705935819679e-05 trainable: 0.00010519177031682276]\n",
      "Val : [regular_loss: 8.939550863988007e-05, trainable_loss: 2.8355128734307508e-05, accuracy: 0.9526379557219958]\n",
      "Epoch 27:\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, train_centerloss, test_centerloss, trained_model = train_with_trainable_loss(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=val_dataset,\n",
    "    model=model, \n",
    "    criterion=criterion,\n",
    "    trainable_criterion=centerloss,\n",
    "    train_dataloader_kwargs=train_dataloader_config,\n",
    "    test_dataloader_kwargs=test_dataloader_config,\n",
    "    training_kwargs=training_config,\n",
    "    device=device,\n",
    "    wandb_instance=wandb,\n",
    "    eval_every=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_plots(train_losses, test_losses, 'ResNet34Grayscale CrossEntropy')\n",
    "show_train_plots(train_centerloss, test_centerloss, 'ResNet34Grayscale Centerloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_ocr_t2.evaluate import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_path = r'/DATA/ichuviliaeva/ocr_data/test.lmdb'\n",
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = LMDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')\n",
    "\n",
    "test_transforms = nn.Sequential(\n",
    "    transforms.Resize((128, 128)),\n",
    ")\n",
    "\n",
    "test_dataset = HWDBDataset(test_helper, transforms=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=8)\n",
    "\n",
    "preds = []\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        logits, _ = trained_model(X.to(torch.float32).to(device))\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)\n",
    "    \n",
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)\n",
    "        \n",
    "test_accuracy = evaluate('./gt.txt', './pred.txt')\n",
    "wandb.run.summary['test_accuracy'] = test_accuracy\n",
    "wandb.run.summary['test_transforms'] = test_transforms\n",
    "\n",
    "torch.save(trained_model.state_dict(), './model.pth')\n",
    "wandb.save('./model.pth')\n",
    "wandb.save('./pred.txt')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
