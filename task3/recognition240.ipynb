{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy9sem/course_cvdl/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -e .\n",
    "#pip install  course_ocr_t3\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('/') / 'DATA' / 'asaginbaev' / 'CourseOCRTask3' \n",
    "\n",
    "TRAIN_PATH, TEST_PATH = DATASET_PATH / 'Train', DATASET_PATH / 'Test'\n",
    "\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "assert TRAIN_PATH.exists(), TRAIN_PATH.absolute()\n",
    "assert TEST_PATH.exists(), TEST_PATH.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8199 100\n",
      "torch.Size([3, 512, 512]) torch.Size([1, 512, 512])\n",
      "torch.Size([3, 512, 512]) 1105913212699e2e8a558191113acbd7.png\n",
      "7380 819\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "import torch.nn as nn\n",
    "from task3pack.utils.data import SegmentationDataset\n",
    "\n",
    "IMAGE_SIZE = [512, 512]\n",
    "NAMES = ['path', 'code', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4', 'barcode']\n",
    "\n",
    "image_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Resize(IMAGE_SIZE),\n",
    "])\n",
    "\n",
    "target_transforms = Compose([\n",
    "    Resize(IMAGE_SIZE),   \n",
    "])\n",
    "\n",
    "train_dataset = SegmentationDataset(csv_path=TRAIN_PATH / 'markup.csv', images_path=TRAIN_PATH / 'Images', csv_header=NAMES, csv_encoding='utf-16', \n",
    "                                   image_transforms=image_transforms, target_transforms=target_transforms, shape=IMAGE_SIZE)\n",
    "test_dataset = SegmentationDataset(csv_path=None, images_path=TEST_PATH / 'Images', csv_header=NAMES, csv_encoding='utf-16', \n",
    "                                   image_transforms=image_transforms, target_transforms=target_transforms, shape=IMAGE_SIZE, is_test=True)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[0][0].shape, train_dataset[0][1].shape)\n",
    "print(test_dataset[0][0].shape, test_dataset[0][1])\n",
    "\n",
    "val_ratio = 0.1\n",
    "val_size = int(len(train_dataset) * val_ratio)\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "print(train_size, val_size)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset,\n",
    "        [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, rect):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    #rect = order_points(pts)\n",
    "    image = np.array(image)\n",
    "    tl, tr, br, bl = rect[0, :], rect[1, :], rect[2, :], rect[3, :]\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_hists(image, thresh_hist=99, thresh_image=50, width=1200):\n",
    "    image = cv2.resize(image, (width, 1000))\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    th, image_th = cv2.threshold(image_gray, thresh_image, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #images = []\n",
    "    hists = []\n",
    "    for i in range(1000 // 100):\n",
    "        img_crop = image_th[i * 100: (i + 1) * 100, :]\n",
    "        vertical_pixel_sum = np.sum(img_crop, axis=0)\n",
    "        myprojection = vertical_pixel_sum / 255\n",
    "        myprojection = np.where(myprojection > thresh_hist, 1, 0)\n",
    "        \n",
    "        #images.append(img_crop)\n",
    "        hists.append(myprojection[np.newaxis, ...])\n",
    "        \n",
    "    return np.concatenate(hists, axis=0)\n",
    "\n",
    "\n",
    "def dump_hists_to_npy(csv_path, images_path, csv_header, width=1200):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    markup = pd.read_csv(csv_path, header=None, encoding='utf-16', names=csv_header)\n",
    "    for idx in tqdm(range(len(markup))):\n",
    "        image_path = images_path / markup.loc[idx, 'path']\n",
    "        \n",
    "        if image_path.exists():\n",
    "            image = Image.open(image_path)\n",
    "            coords = markup.loc[idx, ['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4']].to_numpy(dtype='float32').reshape(4, 2)\n",
    "            warped_image = four_point_transform(image, coords)\n",
    "            hists = get_hists(warped_image, width)\n",
    "            resX = np.concatenate(hists[3:-3], axis=0)\n",
    "            \n",
    "            label = str(markup.loc[idx, 'code'])\n",
    "            \n",
    "            for _ in range(13 - len(label)):\n",
    "                label = '0' + label\n",
    "                \n",
    "            resy = []\n",
    "            for char in label:\n",
    "                resy.append(int(char))\n",
    "            \n",
    "            X.append(resX)\n",
    "            y.append(resy)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def dump_hist_to_npy(csv_path, images_path, csv_header, width=1200):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    markup = pd.read_csv(csv_path, header=None, encoding='utf-16', names=csv_header)\n",
    "    for idx in tqdm(range(len(markup))):\n",
    "        image_path = images_path / markup.loc[idx, 'path']\n",
    "        \n",
    "        if image_path.exists():\n",
    "            image = Image.open(image_path)\n",
    "            coords = markup.loc[idx, ['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4']].to_numpy(dtype='float32').reshape(4, 2)\n",
    "            warped_image = four_point_transform(image, coords)\n",
    "            hists = get_hists(warped_image, width=width)\n",
    "            resX = hists[5]\n",
    "            \n",
    "            label = str(markup.loc[idx, 'code'])\n",
    "            \n",
    "            for _ in range(13 - len(label)):\n",
    "                label = '0' + label\n",
    "                \n",
    "            resy = []\n",
    "            for char in label:\n",
    "                resy.append(int(char))\n",
    "            \n",
    "            X.append(resX)\n",
    "            y.append(resy)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with reference bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## width = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 8199/8199 [21:06<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = dump_hist_to_npy(TRAIN_PATH / 'markup.csv', TRAIN_PATH / 'Images', NAMES)\n",
    "X_train.dump('X_train_ref_single.npy')\n",
    "y_train.dump('y_train_ref_single.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.28it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = dump_hist_to_npy('markup.csv', TEST_PATH / 'Images', NAMES)\n",
    "X_test.dump('X_test_ref_single.npy')\n",
    "y_test.dump('y_test_ref_single.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 8199/8199 [25:26<00:00,  5.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = dump_hists_to_npy(TRAIN_PATH / 'markup.csv', TRAIN_PATH / 'Images', NAMES)\n",
    "X_train.dump('X_train_ref.npy')\n",
    "y_train.dump('y_train_ref.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:28<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = dump_hists_to_npy('markup.csv', TEST_PATH / 'Images', NAMES)\n",
    "X_test.dump('X_test_ref.npy')\n",
    "y_test.dump('y_test_ref.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with unet bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 8197/8197 [37:38<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = dump_hist_to_npy('train_markup.csv', TRAIN_PATH / 'Images', NAMES, width=240)\n",
    "X_train.dump('X_train_ref_single_240.npy')\n",
    "y_train.dump('y_train_ref_single_240.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = dump_hist_to_npy('test_markup.csv', TEST_PATH / 'Images', NAMES, width=240)\n",
    "X_test.dump('X_test_ref_single_240.npy')\n",
    "y_test.dump('y_test_ref_single_240.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.load('./X_train_ref.npy', allow_pickle=True), np.load('./y_train_ref.npy', allow_pickle=True)\n",
    "X_test, y_test = np.load('./X_test_ref.npy', allow_pickle=True), np.load('./y_test_ref.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassifier = XGBClassifier()\n",
    "xgbclassifier.fit(X_train, y_train[:, 0])\n",
    "\n",
    "accuracy_score(xgbclassifier.predict(X_test), y_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.86\n",
      "1 0.86\n",
      "2 0.84\n",
      "3 0.78\n",
      "4 0.74\n",
      "5 0.66\n",
      "6 0.58\n"
     ]
    }
   ],
   "source": [
    "xgbs = []\n",
    "for i in range(y_train.shape[1]):\n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train, y_train[:, i])\n",
    "\n",
    "    print(i, accuracy_score(xgbc.predict(X_test), y_test[:, i]))\n",
    "    xgbs.append(xgbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        loss = model.loss(x, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def eval_loss(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            loss = model.loss(x, y)\n",
    "            total_loss += loss * x.shape[0]\n",
    "        avg_loss = total_loss / len(data_loader.dataset)\n",
    "    return avg_loss.item()\n",
    "\n",
    "\n",
    "def train_epochs(model, train_loader, test_loader, train_args, device):\n",
    "    epochs, lr = train_args['epochs'], train_args['lr']\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = [eval_loss(model, test_loader, device)]\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch {epoch} started')\n",
    "        model.train()\n",
    "        train_losses.extend(train(model, train_loader, optimizer, device))\n",
    "        test_loss = eval_loss(model, test_loader, device)\n",
    "        test_losses.append(test_loss)\n",
    "        print('train loss: {}, test_loss: {}'.format(np.mean(train_losses[-1000:]), \n",
    "                                                     test_losses[-1]))\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_model(train_dataset, test_dataset, model, train_dataloader_kwargs, test_dataloader_kwargs, training_kwargs, device='cpu'):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    test_data: A (n_test, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    model: nn.Model item, should contain function loss and accept\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - trained model\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, **train_dataloader_kwargs)\n",
    "    test_dataloader = DataLoader(test_dataset, **test_dataloader_kwargs)\n",
    "\n",
    "    test_losses.append(eval_loss(model, test_dataloader, device))\n",
    "\n",
    "    train_loss, test_loss = train_epochs(model, train_dataloader, test_dataloader, training_kwargs, device)\n",
    "    test_losses += test_loss\n",
    "    train_losses += train_loss\n",
    "\n",
    "    return np.array(train_losses), np.array(test_losses), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_config = {\n",
    "    'batch_size': 128,\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "test_dataloader_config = {\n",
    "    'batch_size': 128,\n",
    "    'shuffle': False,\n",
    "}\n",
    "\n",
    "learning_config = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 100,\n",
    "}\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, n_outputs=13, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, n_outputs * n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        \n",
    "        result = torch.zeros(x.shape[0], self.n_outputs)\n",
    "        for i in range(self.n_outputs):\n",
    "            result[:, i] = torch.argmax(logits[:, i * self.n_classes: (i + 1) * self.n_classes], dim=-1)\n",
    "         \n",
    "        #result = torch.argmax(logits, -1)    \n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        logits = self.model(x)\n",
    "        \n",
    "        loss = torch.zeros(self.n_outputs)\n",
    "        for i in range(self.n_outputs):\n",
    "            loss[i] = F.cross_entropy(logits[:, i * self.n_classes: (i + 1) * self.n_classes], y[:, i])\n",
    "            \n",
    "        \n",
    "        return loss.sum()\n",
    "        #return F.cross_entropy(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(240, n_outputs=13)\n",
    "\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 7., 5., 5., 7., 2., 1., 9., 6., 7., 0., 5., 8.]]) tensor([2, 0, 0, 5, 0, 0, 3, 7, 0, 8, 8, 1, 4])\n",
      "tensor([[6., 9., 3., 5., 6., 8., 1., 1., 1., 2., 0., 7., 4.]]) tensor([8, 5, 9, 4, 0, 1, 5, 3, 0, 1, 0, 1, 3])\n",
      "tensor([[3., 2., 5., 1., 8., 2., 7., 1., 6., 7., 4., 6., 3.]]) tensor([4, 6, 0, 7, 0, 1, 6, 2, 4, 5, 6, 7, 6])\n",
      "tensor([[1., 5., 5., 9., 6., 3., 2., 9., 8., 6., 4., 2., 5.]]) tensor([4, 6, 0, 2, 8, 2, 4, 0, 1, 9, 4, 2, 6])\n",
      "tensor([[6., 7., 5., 9., 7., 1., 2., 1., 7., 7., 2., 5., 5.]]) tensor([9, 7, 8, 5, 9, 4, 7, 2, 3, 1, 2, 5, 0])\n",
      "tensor([[6., 9., 5., 9., 6., 3., 2., 9., 5., 9., 0., 5., 4.]]) tensor([9, 7, 8, 5, 4, 6, 9, 0, 0, 5, 7, 6, 6])\n",
      "tensor([[1., 6., 6., 2., 0., 2., 7., 9., 1., 7., 9., 2., 8.]]) tensor([9, 7, 8, 5, 9, 8, 1, 2, 4, 1, 1, 2, 3])\n",
      "tensor([[6., 9., 5., 1., 7., 2., 2., 9., 1., 9., 0., 2., 8.]]) tensor([9, 7, 8, 5, 8, 2, 9, 1, 1, 6, 6, 2, 0])\n",
      "tensor([[2., 2., 4., 5., 8., 2., 1., 3., 6., 7., 0., 2., 1.]]) tensor([9, 7, 8, 5, 3, 5, 4, 0, 0, 9, 8, 0, 0])\n",
      "tensor([[3., 3., 5., 9., 1., 2., 6., 1., 5., 2., 0., 7., 4.]]) tensor([9, 7, 8, 5, 9, 5, 7, 9, 0, 0, 9, 4, 8])\n",
      "tensor([[1., 8., 3., 4., 0., 2., 1., 1., 1., 7., 6., 2., 1.]]) tensor([9, 7, 8, 5, 9, 4, 7, 7, 4, 2, 2, 3, 7])\n",
      "tensor([[2., 9., 5., 4., 0., 2., 7., 1., 6., 0., 1., 5., 1.]]) tensor([9, 7, 8, 5, 9, 4, 1, 5, 7, 5, 6, 2, 6])\n",
      "tensor([[1., 9., 5., 4., 6., 2., 1., 1., 6., 8., 9., 2., 8.]]) tensor([9, 7, 8, 0, 1, 9, 4, 7, 0, 2, 2, 5, 6])\n",
      "tensor([[2., 7., 5., 9., 7., 2., 1., 1., 7., 2., 9., 5., 4.]]) tensor([9, 7, 8, 0, 1, 9, 4, 3, 5, 7, 3, 4, 0])\n",
      "tensor([[1., 5., 5., 9., 0., 1., 2., 2., 8., 0., 0., 5., 2.]]) tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 2])\n",
      "tensor([[1., 5., 5., 4., 7., 2., 2., 9., 6., 7., 0., 5., 6.]]) tensor([4, 6, 0, 1, 4, 5, 0, 0, 3, 0, 0, 1, 0])\n",
      "tensor([[8., 3., 5., 9., 4., 2., 2., 1., 2., 2., 0., 5., 8.]]) tensor([4, 6, 1, 0, 0, 0, 8, 5, 2, 1, 6, 7, 2])\n",
      "tensor([[2., 2., 5., 9., 2., 2., 1., 9., 7., 7., 0., 2., 1.]]) tensor([9, 7, 8, 3, 5, 9, 6, 5, 1, 2, 7, 9, 9])\n",
      "tensor([[3., 7., 3., 1., 7., 7., 0., 2., 8., 2., 2., 7., 8.]]) tensor([9, 7, 8, 5, 9, 5, 4, 2, 0, 0, 6, 5, 2])\n",
      "tensor([[3., 3., 5., 9., 7., 2., 1., 3., 7., 9., 0., 7., 3.]]) tensor([9, 7, 8, 5, 6, 9, 9, 5, 3, 1, 8, 9, 9])\n",
      "tensor([[3., 1., 5., 1., 9., 9., 7., 3., 7., 9., 9., 5., 4.]]) tensor([9, 7, 8, 5, 8, 1, 3, 8, 0, 7, 8, 2, 4])\n",
      "tensor([[4., 9., 5., 9., 0., 2., 1., 9., 5., 8., 0., 5., 3.]]) tensor([4, 6, 0, 0, 6, 0, 5, 0, 1, 7, 3, 3, 3])\n",
      "tensor([[1., 9., 5., 9., 7., 2., 7., 9., 6., 7., 1., 5., 8.]]) tensor([4, 6, 8, 0, 0, 0, 1, 8, 2, 0, 0, 1, 0])\n",
      "tensor([[6., 6., 5., 9., 7., 3., 2., 9., 7., 0., 0., 5., 1.]]) tensor([2, 1, 0, 0, 1, 0, 0, 0, 3, 4, 5, 5, 9])\n",
      "tensor([[1., 3., 5., 5., 0., 2., 1., 9., 6., 0., 6., 2., 2.]]) tensor([5, 5, 5, 0, 1, 1, 8, 9, 0, 1, 2, 3, 2])\n",
      "tensor([[2., 7., 6., 9., 0., 1., 1., 9., 5., 0., 0., 5., 9.]]) tensor([4, 6, 0, 7, 1, 2, 9, 6, 3, 5, 3, 5, 7])\n",
      "tensor([[1., 4., 5., 1., 1., 3., 9., 1., 7., 4., 4., 2., 8.]]) tensor([4, 6, 0, 7, 9, 3, 1, 8, 8, 3, 2, 6, 7])\n",
      "tensor([[1., 9., 5., 0., 7., 3., 2., 9., 5., 6., 0., 5., 5.]]) tensor([4, 6, 0, 3, 3, 2, 2, 5, 6, 7, 7, 7, 8])\n",
      "tensor([[1., 0., 5., 9., 7., 2., 1., 9., 7., 7., 0., 2., 6.]]) tensor([4, 6, 0, 3, 2, 2, 3, 0, 6, 9, 7, 7, 7])\n",
      "tensor([[1., 9., 5., 1., 0., 3., 2., 9., 1., 9., 4., 2., 6.]]) tensor([4, 6, 0, 3, 5, 3, 1, 1, 0, 3, 6, 6, 8])\n",
      "tensor([[3., 6., 5., 9., 7., 9., 1., 1., 1., 2., 1., 7., 8.]]) tensor([4, 6, 0, 2, 7, 3, 1, 7, 4, 1, 1, 2, 7])\n",
      "tensor([[2., 1., 6., 4., 5., 3., 1., 9., 1., 7., 4., 2., 5.]]) tensor([2, 4, 0, 0, 0, 0, 0, 0, 0, 6, 4, 1, 1])\n",
      "tensor([[3., 7., 2., 8., 9., 2., 1., 9., 8., 9., 6., 2., 8.]]) tensor([4, 8, 1, 0, 6, 1, 3, 0, 0, 0, 4, 1, 2])\n",
      "tensor([[6., 2., 5., 9., 0., 2., 2., 3., 5., 7., 0., 5., 4.]]) tensor([8, 6, 1, 3, 0, 1, 1, 0, 0, 1, 0, 1, 4])\n",
      "tensor([[6., 9., 5., 4., 9., 1., 9., 0., 9., 0., 0., 5., 4.]]) tensor([3, 8, 0, 0, 0, 1, 0, 6, 4, 3, 7, 6, 4])\n",
      "tensor([[6., 9., 5., 9., 7., 3., 1., 1., 7., 6., 0., 5., 8.]]) tensor([4, 6, 5, 0, 0, 6, 7, 7, 6, 0, 1, 3, 1])\n",
      "tensor([[4., 3., 5., 9., 0., 2., 1., 9., 8., 0., 6., 5., 4.]]) tensor([4, 6, 0, 7, 0, 0, 7, 3, 6, 1, 3, 8, 5])\n",
      "tensor([[6., 6., 5., 1., 7., 2., 9., 1., 8., 9., 4., 2., 5.]]) tensor([6, 9, 3, 9, 5, 4, 0, 5, 8, 8, 8, 8, 1])\n",
      "tensor([[1., 5., 5., 1., 7., 2., 9., 2., 1., 2., 9., 5., 5.]]) tensor([8, 0, 0, 9, 7, 4, 0, 8, 7, 9, 7, 3, 2])\n",
      "tensor([[2., 2., 5., 5., 6., 2., 2., 2., 8., 7., 0., 5., 6.]]) tensor([4, 6, 0, 0, 8, 5, 1, 0, 1, 1, 5, 5, 0])\n",
      "tensor([[1., 9., 5., 1., 7., 3., 2., 9., 8., 0., 0., 5., 1.]]) tensor([4, 8, 1, 2, 3, 0, 2, 0, 0, 0, 0, 5, 5])\n",
      "tensor([[1., 9., 5., 1., 0., 2., 1., 9., 5., 3., 0., 7., 1.]]) tensor([4, 6, 0, 7, 1, 1, 4, 9, 1, 1, 9, 9, 2])\n",
      "tensor([[1., 9., 5., 9., 7., 3., 0., 3., 7., 6., 0., 5., 9.]]) tensor([4, 6, 0, 7, 1, 8, 3, 8, 1, 9, 7, 6, 2])\n",
      "tensor([[6., 8., 4., 9., 7., 2., 9., 1., 7., 2., 0., 5., 1.]]) tensor([4, 6, 3, 0, 0, 1, 4, 8, 5, 1, 5, 8, 7])\n",
      "tensor([[6., 9., 5., 9., 7., 3., 1., 0., 8., 0., 1., 7., 4.]]) tensor([4, 6, 0, 7, 1, 1, 9, 7, 0, 1, 8, 3, 3])\n",
      "tensor([[6., 0., 1., 8., 0., 2., 1., 1., 2., 7., 0., 5., 4.]]) tensor([4, 6, 0, 7, 1, 1, 9, 7, 0, 0, 4, 4, 7])\n",
      "tensor([[1., 2., 5., 1., 1., 3., 1., 1., 8., 7., 0., 5., 4.]]) tensor([4, 6, 8, 0, 0, 2, 1, 8, 8, 2, 2, 9, 6])\n",
      "tensor([[6., 9., 5., 1., 7., 2., 2., 9., 1., 2., 0., 5., 3.]]) tensor([9, 7, 8, 5, 9, 0, 6, 8, 3, 7, 4, 2, 4])\n",
      "tensor([[3., 3., 5., 4., 7., 5., 2., 1., 7., 6., 4., 5., 5.]]) tensor([7, 8, 9, 0, 0, 0, 0, 0, 0, 8, 3, 9, 6])\n",
      "tensor([[8., 9., 5., 9., 5., 2., 2., 1., 1., 7., 9., 2., 5.]]) tensor([6, 9, 4, 1, 0, 5, 7, 4, 0, 4, 8, 5, 1])\n",
      "tensor([[2., 7., 5., 2., 4., 2., 9., 1., 0., 6., 0., 2., 3.]]) tensor([4, 6, 1, 0, 0, 2, 8, 8, 9, 0, 1, 3, 0])\n",
      "tensor([[3., 5., 5., 5., 1., 2., 1., 1., 6., 7., 0., 2., 2.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 2, 0, 1, 9, 3])\n",
      "tensor([[1., 5., 5., 9., 7., 2., 6., 9., 9., 4., 4., 2., 9.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 6, 3, 1, 8])\n",
      "tensor([[4., 9., 5., 1., 4., 1., 1., 9., 7., 0., 0., 5., 4.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 5, 5, 3, 3])\n",
      "tensor([[5., 7., 5., 9., 7., 9., 1., 9., 1., 6., 0., 5., 2.]]) tensor([4, 6, 0, 7, 0, 4, 1, 5, 6, 0, 0, 2, 7])\n",
      "tensor([[2., 9., 1., 5., 7., 2., 7., 1., 1., 0., 6., 5., 6.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 6, 0, 0, 4])\n",
      "tensor([[1., 4., 5., 0., 7., 2., 7., 9., 1., 9., 0., 7., 5.]]) tensor([4, 6, 0, 7, 0, 4, 3, 2, 0, 0, 9, 6, 9])\n",
      "tensor([[1., 3., 5., 4., 7., 3., 2., 2., 8., 7., 0., 5., 3.]]) tensor([4, 6, 7, 0, 0, 0, 1, 8, 4, 0, 6, 5, 1])\n",
      "tensor([[4., 9., 5., 7., 7., 3., 1., 9., 8., 4., 0., 5., 6.]]) tensor([4, 6, 0, 0, 9, 1, 9, 8, 1, 3, 1, 3, 3])\n",
      "tensor([[3., 8., 5., 9., 4., 9., 1., 9., 6., 2., 9., 5., 8.]]) tensor([2, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0])\n",
      "tensor([[3., 5., 5., 9., 7., 3., 1., 9., 1., 0., 4., 2., 2.]]) tensor([2, 0, 4, 0, 0, 0, 0, 4, 4, 9, 4, 3, 8])\n",
      "tensor([[3., 4., 5., 9., 7., 2., 1., 9., 7., 0., 0., 2., 8.]]) tensor([4, 6, 5, 1, 1, 1, 1, 6, 1, 1, 1, 3, 3])\n",
      "tensor([[6., 7., 5., 9., 2., 3., 2., 9., 0., 0., 0., 5., 4.]]) tensor([4, 6, 0, 6, 0, 0, 8, 3, 5, 3, 8, 9, 4])\n",
      "tensor([[6., 9., 5., 9., 4., 2., 7., 3., 7., 9., 2., 2., 5.]]) tensor([4, 6, 0, 6, 1, 8, 0, 0, 0, 3, 6, 8, 6])\n",
      "tensor([[6., 4., 5., 9., 7., 2., 1., 0., 7., 2., 2., 2., 5.]]) tensor([4, 6, 0, 7, 0, 5, 0, 4, 6, 0, 8, 1, 3])\n",
      "tensor([[3., 7., 5., 4., 7., 9., 2., 0., 1., 2., 0., 2., 3.]]) tensor([4, 6, 0, 0, 9, 9, 9, 0, 2, 4, 5, 7, 3])\n",
      "tensor([[3., 8., 5., 9., 0., 5., 1., 3., 7., 0., 2., 2., 5.]]) tensor([4, 6, 0, 7, 0, 3, 5, 8, 9, 0, 5, 3, 6])\n",
      "tensor([[6., 9., 5., 9., 4., 9., 7., 3., 7., 2., 9., 2., 5.]]) tensor([4, 6, 2, 7, 0, 8, 9, 7, 4, 0, 6, 1, 8])\n",
      "tensor([[1., 7., 5., 9., 7., 3., 2., 9., 6., 2., 0., 5., 6.]]) tensor([4, 6, 0, 0, 6, 0, 5, 0, 1, 7, 6, 5, 4])\n",
      "tensor([[6., 9., 5., 9., 4., 9., 7., 3., 7., 9., 2., 7., 5.]]) tensor([9, 7, 8, 5, 9, 6, 9, 3, 0, 3, 0, 8, 9])\n",
      "tensor([[1., 9., 5., 9., 7., 1., 9., 1., 1., 9., 0., 7., 6.]]) tensor([5, 9, 0, 0, 5, 1, 6, 3, 2, 0, 3, 2, 4])\n",
      "tensor([[3., 4., 5., 4., 7., 9., 1., 1., 5., 8., 0., 7., 2.]]) tensor([7, 6, 2, 2, 1, 0, 0, 9, 2, 6, 8, 7, 0])\n",
      "tensor([[5., 4., 5., 5., 7., 3., 2., 9., 1., 7., 0., 5., 4.]]) tensor([4, 6, 0, 7, 0, 3, 1, 2, 4, 0, 6, 9, 4])\n",
      "tensor([[6., 3., 5., 4., 7., 5., 2., 9., 8., 7., 5., 2., 4.]]) tensor([4, 6, 8, 0, 0, 3, 6, 9, 1, 0, 7, 8, 6])\n",
      "tensor([[3., 9., 5., 9., 4., 9., 7., 3., 6., 2., 2., 7., 5.]]) tensor([9, 7, 8, 5, 3, 9, 6, 0, 0, 3, 4, 9, 1])\n",
      "tensor([[6., 2., 5., 5., 4., 9., 7., 0., 6., 2., 2., 7., 5.]]) tensor([9, 7, 8, 5, 3, 9, 6, 0, 0, 4, 5, 7, 3])\n",
      "tensor([[6., 4., 5., 5., 6., 5., 7., 4., 7., 7., 0., 7., 5.]]) tensor([9, 7, 8, 5, 8, 1, 2, 5, 1, 8, 4, 3, 1])\n",
      "tensor([[1., 9., 5., 9., 7., 3., 1., 9., 9., 0., 0., 5., 2.]]) tensor([3, 5, 7, 4, 6, 6, 1, 3, 6, 5, 2, 3, 7])\n",
      "tensor([[1., 0., 0., 7., 7., 1., 1., 9., 1., 7., 0., 2., 6.]]) tensor([4, 6, 0, 0, 9, 4, 9, 1, 2, 3, 1, 3, 4])\n",
      "tensor([[3., 9., 6., 5., 9., 2., 8., 3., 7., 9., 9., 2., 5.]]) tensor([4, 6, 2, 0, 0, 0, 4, 9, 5, 3, 5, 7, 5])\n",
      "tensor([[2., 6., 5., 9., 0., 3., 1., 3., 6., 0., 2., 2., 5.]]) tensor([3, 6, 0, 0, 5, 2, 2, 3, 6, 5, 6, 4, 8])\n",
      "tensor([[6., 9., 5., 9., 4., 9., 7., 3., 7., 0., 2., 7., 5.]]) tensor([9, 7, 8, 5, 9, 3, 0, 1, 0, 0, 2, 6, 6])\n",
      "tensor([[1., 7., 5., 9., 7., 7., 1., 9., 8., 6., 0., 5., 2.]]) tensor([9, 7, 8, 5, 1, 7, 0, 9, 1, 4, 2, 2, 7])\n",
      "tensor([[3., 9., 6., 9., 0., 2., 8., 8., 7., 2., 0., 2., 5.]]) tensor([9, 7, 8, 5, 9, 1, 7, 5, 9, 5, 3, 6, 8])\n",
      "tensor([[3., 9., 5., 9., 4., 2., 1., 3., 7., 0., 0., 2., 5.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 5, 0, 3, 6, 1])\n",
      "tensor([[3., 9., 5., 9., 4., 2., 1., 3., 7., 0., 9., 7., 5.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 5, 2, 1, 1, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 2., 5., 9., 4., 5., 7., 0., 7., 9., 0., 2., 5.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 4, 0, 1, 8, 8])\n",
      "tensor([[1., 9., 5., 9., 7., 2., 3., 9., 7., 0., 9., 7., 5.]]) tensor([5, 0, 1, 0, 9, 9, 3, 3, 8, 8, 0, 8, 0])\n",
      "tensor([[4., 3., 2., 2., 6., 2., 2., 9., 1., 7., 0., 7., 9.]]) tensor([5, 0, 1, 0, 9, 9, 3, 4, 5, 5, 2, 9, 4])\n",
      "tensor([[1., 7., 5., 9., 7., 1., 2., 9., 6., 2., 1., 5., 4.]]) tensor([4, 8, 9, 7, 0, 5, 6, 8, 4, 3, 6, 8, 4])\n",
      "tensor([[5., 9., 6., 9., 4., 2., 3., 9., 6., 9., 0., 2., 2.]]) tensor([4, 6, 0, 2, 7, 0, 1, 2, 0, 1, 4, 8, 7])\n",
      "tensor([[1., 5., 5., 9., 0., 2., 1., 1., 1., 0., 0., 2., 2.]]) tensor([4, 6, 0, 7, 1, 7, 1, 7, 8, 0, 3, 7, 1])\n",
      "tensor([[1., 8., 5., 9., 4., 9., 7., 3., 7., 2., 2., 2., 5.]]) tensor([5, 9, 9, 5, 3, 2, 7, 2, 7, 5, 1, 4, 7])\n",
      "tensor([[6., 7., 5., 0., 7., 3., 6., 1., 5., 7., 9., 5., 7.]]) tensor([9, 7, 8, 5, 1, 7, 0, 7, 3, 6, 3, 6, 2])\n",
      "tensor([[6., 9., 5., 9., 0., 9., 1., 3., 7., 0., 0., 2., 0.]]) tensor([4, 6, 0, 1, 7, 1, 3, 0, 0, 1, 7, 0, 2])\n",
      "tensor([[2., 9., 5., 9., 7., 9., 7., 9., 7., 0., 0., 2., 0.]]) tensor([4, 6, 0, 6, 6, 3, 1, 3, 4, 0, 0, 0, 1])\n",
      "tensor([[1., 4., 5., 9., 7., 2., 1., 1., 1., 2., 4., 5., 1.]]) tensor([9, 0, 0, 1, 4, 1, 4, 2, 0, 4, 0, 4, 7])\n",
      "tensor([[3., 9., 5., 9., 4., 2., 7., 3., 7., 2., 2., 7., 5.]]) tensor([4, 8, 1, 0, 0, 2, 3, 0, 0, 0, 1, 5, 6])\n",
      "tensor([[5., 9., 5., 9., 7., 2., 9., 9., 8., 6., 0., 2., 6.]]) tensor([4, 6, 1, 0, 0, 1, 2, 0, 4, 4, 8, 7, 7])\n",
      "tensor([[3., 9., 5., 9., 4., 9., 1., 3., 7., 0., 2., 7., 5.]]) tensor([4, 7, 4, 0, 0, 1, 8, 1, 3, 5, 3, 0, 6])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset:\n",
    "    pred = model(x[None, ...])\n",
    "    print(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 started\n",
      "train loss: 26.83348693847656, test_loss: 26.622304916381836\n",
      "epoch 1 started\n",
      "train loss: 26.326667976379394, test_loss: 26.192771911621094\n",
      "epoch 2 started\n",
      "train loss: 25.920573982825648, test_loss: 25.173622131347656\n",
      "epoch 3 started\n",
      "train loss: 25.543176812392016, test_loss: 24.9612979888916\n",
      "epoch 4 started\n",
      "train loss: 25.199736322256236, test_loss: 24.167818069458008\n",
      "epoch 5 started\n",
      "train loss: 24.880103018344975, test_loss: 23.782907485961914\n",
      "epoch 6 started\n",
      "train loss: 24.604305904514188, test_loss: 23.335742950439453\n",
      "epoch 7 started\n",
      "train loss: 24.339181067393376, test_loss: 23.321762084960938\n",
      "epoch 8 started\n",
      "train loss: 24.119153826460877, test_loss: 23.104093551635742\n",
      "epoch 9 started\n",
      "train loss: 23.910134761516865, test_loss: 22.871437072753906\n",
      "epoch 10 started\n",
      "train loss: 23.71640740241204, test_loss: 22.91000747680664\n",
      "epoch 11 started\n",
      "train loss: 23.536521226931843, test_loss: 22.703264236450195\n",
      "epoch 12 started\n",
      "train loss: 23.37376711693036, test_loss: 22.655261993408203\n",
      "epoch 13 started\n",
      "train loss: 23.216478662176446, test_loss: 22.541526794433594\n",
      "epoch 14 started\n",
      "train loss: 23.05833735148112, test_loss: 22.900484085083008\n",
      "epoch 15 started\n",
      "train loss: 22.745036334991454, test_loss: 22.578855514526367\n",
      "epoch 16 started\n",
      "train loss: 22.397213048934937, test_loss: 22.556396484375\n",
      "epoch 17 started\n",
      "train loss: 22.07340107345581, test_loss: 22.6849422454834\n",
      "epoch 18 started\n",
      "train loss: 21.780791532516478, test_loss: 22.722644805908203\n",
      "epoch 19 started\n",
      "train loss: 21.511419195175172, test_loss: 22.703847885131836\n",
      "epoch 20 started\n",
      "train loss: 21.284064666748048, test_loss: 22.397785186767578\n",
      "epoch 21 started\n",
      "train loss: 21.057536706924438, test_loss: 22.790964126586914\n",
      "epoch 22 started\n",
      "train loss: 20.8564190120697, test_loss: 22.63823699951172\n",
      "epoch 23 started\n",
      "train loss: 20.66017468070984, test_loss: 22.4036922454834\n",
      "epoch 24 started\n",
      "train loss: 20.46916713142395, test_loss: 22.781848907470703\n",
      "epoch 25 started\n",
      "train loss: 20.292284265518187, test_loss: 22.72431182861328\n",
      "epoch 26 started\n",
      "train loss: 20.114342639923095, test_loss: 22.7280330657959\n",
      "epoch 27 started\n",
      "train loss: 19.93503553390503, test_loss: 22.880088806152344\n",
      "epoch 28 started\n",
      "train loss: 19.760159385681153, test_loss: 22.7097110748291\n",
      "epoch 29 started\n",
      "train loss: 19.589048818588257, test_loss: 22.88656997680664\n",
      "epoch 30 started\n",
      "train loss: 19.429065702438354, test_loss: 23.227012634277344\n",
      "epoch 31 started\n",
      "train loss: 19.266771374702454, test_loss: 23.051576614379883\n",
      "epoch 32 started\n",
      "train loss: 19.11848152446747, test_loss: 22.938573837280273\n",
      "epoch 33 started\n",
      "train loss: 18.963733052253723, test_loss: 23.071212768554688\n",
      "epoch 34 started\n",
      "train loss: 18.821992208480836, test_loss: 23.080284118652344\n",
      "epoch 35 started\n",
      "train loss: 18.675807504653932, test_loss: 23.139625549316406\n",
      "epoch 36 started\n",
      "train loss: 18.55237118244171, test_loss: 23.27558135986328\n",
      "epoch 37 started\n",
      "train loss: 18.41666752052307, test_loss: 23.332477569580078\n",
      "epoch 38 started\n",
      "train loss: 18.271698999404908, test_loss: 23.264986038208008\n",
      "epoch 39 started\n",
      "train loss: 18.15951176929474, test_loss: 23.21282386779785\n",
      "epoch 40 started\n",
      "train loss: 18.023277609825133, test_loss: 23.213886260986328\n",
      "epoch 41 started\n",
      "train loss: 17.916138574600218, test_loss: 23.464523315429688\n",
      "epoch 42 started\n",
      "train loss: 17.819783308029177, test_loss: 23.394489288330078\n",
      "epoch 43 started\n",
      "train loss: 17.711201389312745, test_loss: 23.626169204711914\n",
      "epoch 44 started\n",
      "train loss: 17.60008179664612, test_loss: 23.87188720703125\n",
      "epoch 45 started\n",
      "train loss: 17.494410948753355, test_loss: 23.77853012084961\n",
      "epoch 46 started\n",
      "train loss: 17.396049057006834, test_loss: 23.498001098632812\n",
      "epoch 47 started\n",
      "train loss: 17.29924143600464, test_loss: 23.667072296142578\n",
      "epoch 48 started\n",
      "train loss: 17.20328031539917, test_loss: 24.036972045898438\n",
      "epoch 49 started\n",
      "train loss: 17.10070703792572, test_loss: 24.113767623901367\n",
      "epoch 50 started\n",
      "train loss: 16.998795340538024, test_loss: 24.067411422729492\n",
      "epoch 51 started\n",
      "train loss: 16.906207942962645, test_loss: 24.353914260864258\n",
      "epoch 52 started\n",
      "train loss: 16.825563151359557, test_loss: 24.243881225585938\n",
      "epoch 53 started\n",
      "train loss: 16.74210606479645, test_loss: 24.002653121948242\n",
      "epoch 54 started\n",
      "train loss: 16.665181743621826, test_loss: 23.968643188476562\n",
      "epoch 55 started\n",
      "train loss: 16.573279485702514, test_loss: 24.20201873779297\n",
      "epoch 56 started\n",
      "train loss: 16.48692810058594, test_loss: 24.413068771362305\n",
      "epoch 57 started\n",
      "train loss: 16.40812786579132, test_loss: 24.52273178100586\n",
      "epoch 58 started\n",
      "train loss: 16.32547988796234, test_loss: 24.569868087768555\n",
      "epoch 59 started\n",
      "train loss: 16.245341586112975, test_loss: 24.573720932006836\n",
      "epoch 60 started\n",
      "train loss: 16.17462910556793, test_loss: 24.588523864746094\n",
      "epoch 61 started\n",
      "train loss: 16.099019183158873, test_loss: 24.815956115722656\n",
      "epoch 62 started\n",
      "train loss: 16.02435275554657, test_loss: 24.85037612915039\n",
      "epoch 63 started\n",
      "train loss: 15.95646753025055, test_loss: 24.795917510986328\n",
      "epoch 64 started\n",
      "train loss: 15.893477412223817, test_loss: 24.923927307128906\n",
      "epoch 65 started\n",
      "train loss: 15.847717797279358, test_loss: 24.89958953857422\n",
      "epoch 66 started\n",
      "train loss: 15.785575823783875, test_loss: 24.948902130126953\n",
      "epoch 67 started\n",
      "train loss: 15.720860906600953, test_loss: 24.91259002685547\n",
      "epoch 68 started\n",
      "train loss: 15.656035458564759, test_loss: 25.13717269897461\n",
      "epoch 69 started\n",
      "train loss: 15.59867108440399, test_loss: 25.018787384033203\n",
      "epoch 70 started\n",
      "train loss: 15.547777018547059, test_loss: 24.836198806762695\n",
      "epoch 71 started\n",
      "train loss: 15.489946852684021, test_loss: 25.201580047607422\n",
      "epoch 72 started\n",
      "train loss: 15.441182936668396, test_loss: 25.240245819091797\n",
      "epoch 73 started\n",
      "train loss: 15.364506883621216, test_loss: 25.221818923950195\n",
      "epoch 74 started\n",
      "train loss: 15.317898696899414, test_loss: 25.3045711517334\n",
      "epoch 75 started\n",
      "train loss: 15.261056139945984, test_loss: 25.640962600708008\n",
      "epoch 76 started\n",
      "train loss: 15.233889147758484, test_loss: 25.188566207885742\n",
      "epoch 77 started\n",
      "train loss: 15.17576249885559, test_loss: 25.166433334350586\n",
      "epoch 78 started\n",
      "train loss: 15.1296752576828, test_loss: 25.400978088378906\n",
      "epoch 79 started\n",
      "train loss: 15.093463236808777, test_loss: 25.45903968811035\n",
      "epoch 80 started\n",
      "train loss: 15.041071734428407, test_loss: 25.862098693847656\n",
      "epoch 81 started\n",
      "train loss: 15.000315263748169, test_loss: 25.573049545288086\n",
      "epoch 82 started\n",
      "train loss: 14.962437147140504, test_loss: 25.500478744506836\n",
      "epoch 83 started\n",
      "train loss: 14.914376106262207, test_loss: 25.763357162475586\n",
      "epoch 84 started\n",
      "train loss: 14.881576336860658, test_loss: 25.964155197143555\n",
      "epoch 85 started\n",
      "train loss: 14.833842449188232, test_loss: 25.89844512939453\n",
      "epoch 86 started\n",
      "train loss: 14.8045646276474, test_loss: 26.163063049316406\n",
      "epoch 87 started\n",
      "train loss: 14.76198017501831, test_loss: 25.83782958984375\n",
      "epoch 88 started\n",
      "train loss: 14.715276070594788, test_loss: 26.182775497436523\n",
      "epoch 89 started\n",
      "train loss: 14.6781644449234, test_loss: 26.170726776123047\n",
      "epoch 90 started\n",
      "train loss: 14.645971471786499, test_loss: 26.34332275390625\n",
      "epoch 91 started\n",
      "train loss: 14.609779753684997, test_loss: 26.04962921142578\n",
      "epoch 92 started\n",
      "train loss: 14.572842664718628, test_loss: 26.315998077392578\n",
      "epoch 93 started\n",
      "train loss: 14.532236408233642, test_loss: 25.919191360473633\n",
      "epoch 94 started\n",
      "train loss: 14.493524922370911, test_loss: 26.234407424926758\n",
      "epoch 95 started\n",
      "train loss: 14.44825353860855, test_loss: 26.212512969970703\n",
      "epoch 96 started\n",
      "train loss: 14.396545579910278, test_loss: 26.34618377685547\n",
      "epoch 97 started\n",
      "train loss: 14.362891976356506, test_loss: 26.562061309814453\n",
      "epoch 98 started\n",
      "train loss: 14.325563509941102, test_loss: 26.524328231811523\n",
      "epoch 99 started\n",
      "train loss: 14.305580145835876, test_loss: 26.07170867919922\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, trained_model = train_model(train_dataset, test_dataset, model, train_dataloader_config, test_dataloader_config, learning_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 6., 0., 0., 4., 9., 3., 4., 0., 0., 0., 9., 0.]]) tensor([2, 0, 0, 5, 0, 0, 3, 7, 0, 8, 8, 1, 4])\n",
      "tensor([[4., 0., 0., 0., 1., 0., 3., 2., 1., 0., 0., 4., 3.]]) tensor([8, 5, 9, 4, 0, 1, 5, 3, 0, 1, 0, 1, 3])\n",
      "tensor([[4., 6., 0., 7., 0., 1., 6., 2., 4., 5., 8., 8., 8.]]) tensor([4, 6, 0, 7, 0, 1, 6, 2, 4, 5, 6, 7, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 2, 8, 2, 4, 0, 1, 9, 4, 2, 6])\n",
      "tensor([[4., 6., 0., 0., 3., 6., 3., 7., 2., 5., 0., 4., 9.]]) tensor([9, 7, 8, 5, 9, 4, 7, 2, 3, 1, 2, 5, 0])\n",
      "tensor([[9., 7., 8., 5., 0., 0., 0., 0., 0., 7., 8., 8., 8.]]) tensor([9, 7, 8, 5, 4, 6, 9, 0, 0, 5, 7, 6, 6])\n",
      "tensor([[4., 6., 0., 0., 1., 8., 2., 0., 6., 0., 4., 4., 9.]]) tensor([9, 7, 8, 5, 9, 8, 1, 2, 4, 1, 1, 2, 3])\n",
      "tensor([[9., 7., 8., 5., 0., 6., 0., 0., 0., 0., 3., 1., 7.]]) tensor([9, 7, 8, 5, 8, 2, 9, 1, 1, 6, 6, 2, 0])\n",
      "tensor([[9., 7., 8., 5., 3., 5., 8., 0., 0., 9., 8., 0., 0.]]) tensor([9, 7, 8, 5, 3, 5, 4, 0, 0, 9, 8, 0, 0])\n",
      "tensor([[9., 7., 8., 5., 9., 5., 5., 0., 0., 0., 0., 4., 7.]]) tensor([9, 7, 8, 5, 9, 5, 7, 9, 0, 0, 9, 4, 8])\n",
      "tensor([[9., 7., 8., 5., 9., 4., 7., 7., 4., 2., 2., 3., 3.]]) tensor([9, 7, 8, 5, 9, 4, 7, 7, 4, 2, 2, 3, 7])\n",
      "tensor([[9., 7., 8., 5., 6., 9., 1., 5., 3., 5., 7., 2., 6.]]) tensor([9, 7, 8, 5, 9, 4, 1, 5, 7, 5, 6, 2, 6])\n",
      "tensor([[8., 7., 7., 8., 8., 2., 2., 8., 0., 2., 2., 5., 7.]]) tensor([9, 7, 8, 0, 1, 9, 4, 7, 0, 2, 2, 5, 6])\n",
      "tensor([[3., 8., 7., 0., 8., 0., 6., 7., 4., 2., 8., 5., 9.]]) tensor([9, 7, 8, 0, 1, 9, 4, 3, 5, 7, 3, 4, 0])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0.]]) tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 2])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 1, 4, 5, 0, 0, 3, 0, 0, 1, 0])\n",
      "tensor([[4., 6., 8., 0., 0., 1., 6., 5., 4., 1., 0., 7., 2.]]) tensor([4, 6, 1, 0, 0, 0, 8, 5, 2, 1, 6, 7, 2])\n",
      "tensor([[4., 8., 0., 0., 1., 9., 7., 5., 1., 2., 3., 9., 4.]]) tensor([9, 7, 8, 3, 5, 9, 6, 5, 1, 2, 7, 9, 9])\n",
      "tensor([[2., 7., 8., 0., 4., 3., 5., 7., 0., 0., 0., 3., 4.]]) tensor([9, 7, 8, 5, 9, 5, 4, 2, 0, 0, 6, 5, 2])\n",
      "tensor([[5., 9., 0., 5., 3., 0., 9., 0., 3., 1., 7., 0., 4.]]) tensor([9, 7, 8, 5, 6, 9, 9, 5, 3, 1, 8, 9, 9])\n",
      "tensor([[4., 6., 0., 1., 0., 1., 8., 2., 1., 3., 7., 4., 4.]]) tensor([9, 7, 8, 5, 8, 1, 3, 8, 0, 7, 8, 2, 4])\n",
      "tensor([[4., 6., 5., 0., 0., 2., 0., 1., 2., 0., 0., 1., 4.]]) tensor([4, 6, 0, 0, 6, 0, 5, 0, 1, 7, 3, 3, 3])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 4., 0., 0., 0., 6., 8., 4.]]) tensor([4, 6, 8, 0, 0, 0, 1, 8, 2, 0, 0, 1, 0])\n",
      "tensor([[4., 0., 0., 0., 5., 0., 0., 0., 0., 4., 2., 2., 9.]]) tensor([2, 1, 0, 0, 1, 0, 0, 0, 3, 4, 5, 5, 9])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 2., 0., 0., 0., 1., 7., 5.]]) tensor([5, 5, 5, 0, 1, 1, 8, 9, 0, 1, 2, 3, 2])\n",
      "tensor([[4., 6., 0., 7., 1., 2., 2., 7., 8., 5., 3., 5., 3.]]) tensor([4, 6, 0, 7, 1, 2, 9, 6, 3, 5, 3, 5, 7])\n",
      "tensor([[4., 6., 0., 7., 0., 3., 1., 3., 7., 3., 2., 5., 7.]]) tensor([4, 6, 0, 7, 9, 3, 1, 8, 8, 3, 2, 6, 7])\n",
      "tensor([[4., 6., 0., 6., 0., 0., 8., 2., 0., 8., 3., 7., 7.]]) tensor([4, 6, 0, 3, 3, 2, 2, 5, 6, 7, 7, 7, 8])\n",
      "tensor([[4., 6., 0., 7., 0., 0., 1., 0., 3., 0., 2., 7., 8.]]) tensor([4, 6, 0, 3, 2, 2, 3, 0, 6, 9, 7, 7, 7])\n",
      "tensor([[4., 6., 0., 3., 7., 3., 2., 0., 0., 3., 8., 8., 8.]]) tensor([4, 6, 0, 3, 5, 3, 1, 1, 0, 3, 6, 6, 8])\n",
      "tensor([[4., 6., 0., 2., 0., 3., 8., 7., 6., 0., 2., 5., 9.]]) tensor([4, 6, 0, 2, 7, 3, 1, 7, 4, 1, 1, 2, 7])\n",
      "tensor([[3., 2., 3., 3., 7., 2., 8., 5., 3., 9., 1., 4., 3.]]) tensor([2, 4, 0, 0, 0, 0, 0, 0, 0, 6, 4, 1, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 8., 0., 0., 0., 4., 0., 5.]]) tensor([4, 8, 1, 0, 6, 1, 3, 0, 0, 0, 4, 1, 2])\n",
      "tensor([[4., 6., 1., 3., 0., 1., 5., 0., 0., 1., 0., 1., 4.]]) tensor([8, 6, 1, 3, 0, 1, 1, 0, 0, 1, 0, 1, 4])\n",
      "tensor([[3., 8., 0., 0., 7., 1., 0., 3., 4., 3., 3., 3., 4.]]) tensor([3, 8, 0, 0, 0, 1, 0, 6, 4, 3, 7, 6, 4])\n",
      "tensor([[4., 6., 1., 2., 7., 1., 1., 3., 3., 0., 1., 7., 4.]]) tensor([4, 6, 5, 0, 0, 6, 7, 7, 6, 0, 1, 3, 1])\n",
      "tensor([[4., 6., 0., 7., 0., 0., 3., 7., 7., 1., 7., 0., 5.]]) tensor([4, 6, 0, 7, 0, 0, 7, 3, 6, 1, 3, 8, 5])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([6, 9, 3, 9, 5, 4, 0, 5, 8, 8, 8, 8, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([8, 0, 0, 9, 7, 4, 0, 8, 7, 9, 7, 3, 2])\n",
      "tensor([[4., 6., 0., 0., 7., 5., 0., 0., 1., 7., 5., 4., 0.]]) tensor([4, 6, 0, 0, 8, 5, 1, 0, 1, 1, 5, 5, 0])\n",
      "tensor([[4., 8., 1., 1., 3., 0., 9., 0., 0., 0., 0., 5., 5.]]) tensor([4, 8, 1, 2, 3, 0, 2, 0, 0, 0, 0, 5, 5])\n",
      "tensor([[4., 6., 0., 7., 1., 1., 4., 0., 1., 1., 0., 0., 2.]]) tensor([4, 6, 0, 7, 1, 1, 4, 9, 1, 1, 9, 9, 2])\n",
      "tensor([[4., 6., 0., 7., 1., 6., 3., 7., 1., 0., 3., 6., 1.]]) tensor([4, 6, 0, 7, 1, 8, 3, 8, 1, 9, 7, 6, 2])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 3, 0, 0, 1, 4, 8, 5, 1, 5, 8, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 7, 1, 1, 9, 7, 0, 1, 8, 3, 3])\n",
      "tensor([[5., 9., 0., 1., 0., 1., 7., 4., 0., 5., 3., 9., 8.]]) tensor([4, 6, 0, 7, 1, 1, 9, 7, 0, 0, 4, 4, 7])\n",
      "tensor([[4., 6., 8., 0., 0., 0., 4., 8., 3., 1., 2., 9., 7.]]) tensor([4, 6, 8, 0, 0, 2, 1, 8, 8, 2, 2, 9, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([9, 7, 8, 5, 9, 0, 6, 8, 3, 7, 4, 2, 4])\n",
      "tensor([[4., 9., 0., 2., 0., 0., 1., 4., 0., 6., 1., 0., 3.]]) tensor([7, 8, 9, 0, 0, 0, 0, 0, 0, 8, 3, 9, 6])\n",
      "tensor([[6., 9., 4., 1., 0., 5., 7., 4., 0., 2., 8., 5., 1.]]) tensor([6, 9, 4, 1, 0, 5, 7, 4, 0, 4, 8, 5, 1])\n",
      "tensor([[4., 6., 1., 0., 0., 0., 7., 3., 0., 0., 8., 3., 3.]]) tensor([4, 6, 1, 0, 0, 2, 8, 8, 9, 0, 1, 3, 0])\n",
      "tensor([[4., 6., 0., 7., 2., 4., 6., 0., 2., 0., 1., 9., 7.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 2, 0, 1, 9, 3])\n",
      "tensor([[4., 6., 0., 1., 2., 4., 8., 0., 1., 8., 8., 1., 7.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 6, 3, 1, 8])\n",
      "tensor([[4., 6., 0., 5., 2., 4., 6., 0., 1., 5., 5., 8., 7.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 5, 5, 3, 3])\n",
      "tensor([[4., 6., 0., 0., 0., 4., 9., 0., 0., 5., 0., 2., 9.]]) tensor([4, 6, 0, 7, 0, 4, 1, 5, 6, 0, 0, 2, 7])\n",
      "tensor([[4., 6., 0., 1., 2., 4., 6., 0., 1., 8., 0., 0., 4.]]) tensor([4, 6, 0, 1, 2, 4, 8, 0, 1, 6, 0, 0, 4])\n",
      "tensor([[4., 6., 0., 7., 0., 1., 7., 5., 5., 1., 6., 6., 0.]]) tensor([4, 6, 0, 7, 0, 4, 3, 2, 0, 0, 9, 6, 9])\n",
      "tensor([[4., 6., 7., 0., 0., 0., 1., 8., 4., 0., 7., 5., 1.]]) tensor([4, 6, 7, 0, 0, 0, 1, 8, 4, 0, 6, 5, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 1., 9., 5., 0., 3., 0., 7., 8.]]) tensor([4, 6, 0, 0, 9, 1, 9, 8, 1, 3, 1, 3, 3])\n",
      "tensor([[5., 0., 0., 0., 0., 0., 0., 0., 1., 0., 7., 1., 1.]]) tensor([2, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0])\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 4., 4., 9., 4., 7., 8.]]) tensor([2, 0, 4, 0, 0, 0, 0, 4, 4, 9, 4, 3, 8])\n",
      "tensor([[5., 6., 0., 4., 2., 1., 0., 2., 8., 1., 1., 4., 6.]]) tensor([4, 6, 5, 1, 1, 1, 1, 6, 1, 1, 1, 3, 3])\n",
      "tensor([[4., 6., 0., 6., 0., 0., 3., 3., 5., 7., 6., 9., 4.]]) tensor([4, 6, 0, 6, 0, 0, 8, 3, 5, 3, 8, 9, 4])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 6, 0, 6, 1, 8, 0, 0, 0, 3, 6, 8, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 4., 0., 0., 0., 0., 2., 1.]]) tensor([4, 6, 0, 7, 0, 5, 0, 4, 6, 0, 8, 1, 3])\n",
      "tensor([[3., 5., 0., 5., 6., 0., 4., 1., 0., 0., 4., 5., 1.]]) tensor([4, 6, 0, 0, 9, 9, 9, 0, 2, 4, 5, 7, 3])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 6, 0, 7, 0, 3, 5, 8, 9, 0, 5, 3, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 6, 2, 7, 0, 8, 9, 7, 4, 0, 6, 1, 8])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 0, 6, 0, 5, 0, 1, 7, 6, 5, 4])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([9, 7, 8, 5, 9, 6, 9, 3, 0, 3, 0, 8, 9])\n",
      "tensor([[5., 9., 0., 0., 5., 1., 6., 8., 2., 0., 3., 1., 4.]]) tensor([5, 9, 0, 0, 5, 1, 6, 3, 2, 0, 3, 2, 4])\n",
      "tensor([[4., 6., 0., 0., 5., 1., 3., 1., 5., 5., 8., 6., 8.]]) tensor([7, 6, 2, 2, 1, 0, 0, 9, 2, 6, 8, 7, 0])\n",
      "tensor([[5., 9., 1., 0., 2., 8., 0., 0., 5., 0., 6., 0., 4.]]) tensor([4, 6, 0, 7, 0, 3, 1, 2, 4, 0, 6, 9, 4])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 9., 0., 0., 1., 9., 6., 6.]]) tensor([4, 6, 8, 0, 0, 3, 6, 9, 1, 0, 7, 8, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([9, 7, 8, 5, 3, 9, 6, 0, 0, 3, 4, 9, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([9, 7, 8, 5, 3, 9, 6, 0, 0, 4, 5, 7, 3])\n",
      "tensor([[4., 6., 0., 3., 1., 0., 5., 0., 0., 0., 2., 1., 2.]]) tensor([9, 7, 8, 5, 8, 1, 2, 5, 1, 8, 4, 3, 1])\n",
      "tensor([[5., 1., 0., 1., 7., 4., 8., 2., 7., 8., 4., 1., 7.]]) tensor([3, 5, 7, 4, 6, 6, 1, 3, 6, 5, 2, 3, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 0, 9, 4, 9, 1, 2, 3, 1, 3, 4])\n",
      "tensor([[4., 6., 0., 7., 0., 1., 5., 7., 0., 5., 3., 8., 4.]]) tensor([4, 6, 2, 0, 0, 0, 4, 9, 5, 3, 5, 7, 5])\n",
      "tensor([[4., 6., 0., 6., 0., 2., 6., 2., 9., 1., 2., 1., 7.]]) tensor([3, 6, 0, 0, 5, 2, 2, 3, 6, 5, 6, 4, 8])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([9, 7, 8, 5, 9, 3, 0, 1, 0, 0, 2, 6, 6])\n",
      "tensor([[4., 6., 0., 7., 0., 2., 3., 5., 0., 9., 4., 2., 2.]]) tensor([9, 7, 8, 5, 1, 7, 0, 9, 1, 4, 2, 2, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 4., 0., 0., 0., 0., 8., 9.]]) tensor([9, 7, 8, 5, 9, 1, 7, 5, 9, 5, 3, 6, 8])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 5, 0, 3, 6, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 5, 2, 1, 1, 2])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 5., 2.]]) tensor([5, 0, 5, 4, 1, 3, 1, 0, 4, 0, 1, 8, 8])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 8., 7.]]) tensor([5, 0, 1, 0, 9, 9, 3, 3, 8, 8, 0, 8, 0])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([5, 0, 1, 0, 9, 9, 3, 4, 5, 5, 2, 9, 4])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 8, 9, 7, 0, 5, 6, 8, 4, 3, 6, 8, 4])\n",
      "tensor([[4., 9., 0., 1., 2., 2., 7., 2., 0., 2., 7., 2., 2.]]) tensor([4, 6, 0, 2, 7, 0, 1, 2, 0, 1, 4, 8, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 0, 7, 1, 7, 1, 7, 8, 0, 3, 7, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([5, 9, 9, 5, 3, 2, 7, 2, 7, 5, 1, 4, 7])\n",
      "tensor([[9., 7., 8., 5., 1., 7., 0., 8., 7., 6., 8., 7., 2.]]) tensor([9, 7, 8, 5, 1, 7, 0, 7, 3, 6, 3, 6, 2])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 6, 0, 1, 7, 1, 3, 0, 0, 1, 7, 0, 2])\n",
      "tensor([[5., 6., 0., 0., 0., 0., 0., 0., 0., 4., 1., 3., 9.]]) tensor([4, 6, 0, 6, 6, 3, 1, 3, 4, 0, 0, 0, 1])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([9, 0, 0, 1, 4, 1, 4, 2, 0, 4, 0, 4, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 8, 1, 0, 0, 2, 3, 0, 0, 0, 1, 5, 6])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 6.]]) tensor([4, 6, 1, 0, 0, 1, 2, 0, 4, 4, 8, 7, 7])\n",
      "tensor([[4., 6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 9.]]) tensor([4, 7, 4, 0, 0, 1, 8, 1, 3, 5, 3, 0, 6])\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for x, y in test_dataset:\n",
    "    pred = trained_model(x[None, ...])\n",
    "    print(pred, y)\n",
    "    res.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 6. 0. 0. 4. 9. 3. 4. 0. 0. 0. 9. 0.]]\n",
      "[[4. 0. 0. 0. 1. 0. 3. 2. 1. 0. 0. 4. 3.]]\n",
      "[[4. 6. 0. 7. 0. 1. 6. 2. 4. 5. 8. 8. 8.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 3. 6. 3. 7. 2. 5. 0. 4. 9.]]\n",
      "[[9. 7. 8. 5. 0. 0. 0. 0. 0. 7. 8. 8. 8.]]\n",
      "[[4. 6. 0. 0. 1. 8. 2. 0. 6. 0. 4. 4. 9.]]\n",
      "[[9. 7. 8. 5. 0. 6. 0. 0. 0. 0. 3. 1. 7.]]\n",
      "[[9. 7. 8. 5. 3. 5. 8. 0. 0. 9. 8. 0. 0.]]\n",
      "[[9. 7. 8. 5. 9. 5. 5. 0. 0. 0. 0. 4. 7.]]\n",
      "[[9. 7. 8. 5. 9. 4. 7. 7. 4. 2. 2. 3. 3.]]\n",
      "[[9. 7. 8. 5. 6. 9. 1. 5. 3. 5. 7. 2. 6.]]\n",
      "[[8. 7. 7. 8. 8. 2. 2. 8. 0. 2. 2. 5. 7.]]\n",
      "[[3. 8. 7. 0. 8. 0. 6. 7. 4. 2. 8. 5. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 8. 0. 0. 1. 6. 5. 4. 1. 0. 7. 2.]]\n",
      "[[4. 8. 0. 0. 1. 9. 7. 5. 1. 2. 3. 9. 4.]]\n",
      "[[2. 7. 8. 0. 4. 3. 5. 7. 0. 0. 0. 3. 4.]]\n",
      "[[5. 9. 0. 5. 3. 0. 9. 0. 3. 1. 7. 0. 4.]]\n",
      "[[4. 6. 0. 1. 0. 1. 8. 2. 1. 3. 7. 4. 4.]]\n",
      "[[4. 6. 5. 0. 0. 2. 0. 1. 2. 0. 0. 1. 4.]]\n",
      "[[4. 6. 0. 0. 0. 0. 4. 0. 0. 0. 6. 8. 4.]]\n",
      "[[4. 0. 0. 0. 5. 0. 0. 0. 0. 4. 2. 2. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 2. 0. 0. 0. 1. 7. 5.]]\n",
      "[[4. 6. 0. 7. 1. 2. 2. 7. 8. 5. 3. 5. 3.]]\n",
      "[[4. 6. 0. 7. 0. 3. 1. 3. 7. 3. 2. 5. 7.]]\n",
      "[[4. 6. 0. 6. 0. 0. 8. 2. 0. 8. 3. 7. 7.]]\n",
      "[[4. 6. 0. 7. 0. 0. 1. 0. 3. 0. 2. 7. 8.]]\n",
      "[[4. 6. 0. 3. 7. 3. 2. 0. 0. 3. 8. 8. 8.]]\n",
      "[[4. 6. 0. 2. 0. 3. 8. 7. 6. 0. 2. 5. 9.]]\n",
      "[[3. 2. 3. 3. 7. 2. 8. 5. 3. 9. 1. 4. 3.]]\n",
      "[[4. 6. 0. 0. 0. 0. 8. 0. 0. 0. 4. 0. 5.]]\n",
      "[[4. 6. 1. 3. 0. 1. 5. 0. 0. 1. 0. 1. 4.]]\n",
      "[[3. 8. 0. 0. 7. 1. 0. 3. 4. 3. 3. 3. 4.]]\n",
      "[[4. 6. 1. 2. 7. 1. 1. 3. 3. 0. 1. 7. 4.]]\n",
      "[[4. 6. 0. 7. 0. 0. 3. 7. 7. 1. 7. 0. 5.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 7. 5. 0. 0. 1. 7. 5. 4. 0.]]\n",
      "[[4. 8. 1. 1. 3. 0. 9. 0. 0. 0. 0. 5. 5.]]\n",
      "[[4. 6. 0. 7. 1. 1. 4. 0. 1. 1. 0. 0. 2.]]\n",
      "[[4. 6. 0. 7. 1. 6. 3. 7. 1. 0. 3. 6. 1.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[5. 9. 0. 1. 0. 1. 7. 4. 0. 5. 3. 9. 8.]]\n",
      "[[4. 6. 8. 0. 0. 0. 4. 8. 3. 1. 2. 9. 7.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 9. 0. 2. 0. 0. 1. 4. 0. 6. 1. 0. 3.]]\n",
      "[[6. 9. 4. 1. 0. 5. 7. 4. 0. 2. 8. 5. 1.]]\n",
      "[[4. 6. 1. 0. 0. 0. 7. 3. 0. 0. 8. 3. 3.]]\n",
      "[[4. 6. 0. 7. 2. 4. 6. 0. 2. 0. 1. 9. 7.]]\n",
      "[[4. 6. 0. 1. 2. 4. 8. 0. 1. 8. 8. 1. 7.]]\n",
      "[[4. 6. 0. 5. 2. 4. 6. 0. 1. 5. 5. 8. 7.]]\n",
      "[[4. 6. 0. 0. 0. 4. 9. 0. 0. 5. 0. 2. 9.]]\n",
      "[[4. 6. 0. 1. 2. 4. 6. 0. 1. 8. 0. 0. 4.]]\n",
      "[[4. 6. 0. 7. 0. 1. 7. 5. 5. 1. 6. 6. 0.]]\n",
      "[[4. 6. 7. 0. 0. 0. 1. 8. 4. 0. 7. 5. 1.]]\n",
      "[[4. 6. 0. 0. 0. 1. 9. 5. 0. 3. 0. 7. 8.]]\n",
      "[[5. 0. 0. 0. 0. 0. 0. 0. 1. 0. 7. 1. 1.]]\n",
      "[[2. 0. 0. 0. 0. 0. 0. 4. 4. 9. 4. 7. 8.]]\n",
      "[[5. 6. 0. 4. 2. 1. 0. 2. 8. 1. 1. 4. 6.]]\n",
      "[[4. 6. 0. 6. 0. 0. 3. 3. 5. 7. 6. 9. 4.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 4. 0. 0. 0. 0. 2. 1.]]\n",
      "[[3. 5. 0. 5. 6. 0. 4. 1. 0. 0. 4. 5. 1.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[5. 9. 0. 0. 5. 1. 6. 8. 2. 0. 3. 1. 4.]]\n",
      "[[4. 6. 0. 0. 5. 1. 3. 1. 5. 5. 8. 6. 8.]]\n",
      "[[5. 9. 1. 0. 2. 8. 0. 0. 5. 0. 6. 0. 4.]]\n",
      "[[4. 6. 0. 0. 0. 0. 9. 0. 0. 1. 9. 6. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 3. 1. 0. 5. 0. 0. 0. 2. 1. 2.]]\n",
      "[[5. 1. 0. 1. 7. 4. 8. 2. 7. 8. 4. 1. 7.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 7. 0. 1. 5. 7. 0. 5. 3. 8. 4.]]\n",
      "[[4. 6. 0. 6. 0. 2. 6. 2. 9. 1. 2. 1. 7.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 7. 0. 2. 3. 5. 0. 9. 4. 2. 2.]]\n",
      "[[4. 6. 0. 0. 0. 0. 4. 0. 0. 0. 0. 8. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 2.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 8. 7.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 9. 0. 1. 2. 2. 7. 2. 0. 2. 7. 2. 2.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[9. 7. 8. 5. 1. 7. 0. 8. 7. 6. 8. 7. 2.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[5. 6. 0. 0. 0. 0. 0. 0. 0. 4. 1. 3. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 6.]]\n",
      "[[4. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 9.]]\n"
     ]
    }
   ],
   "source": [
    "test_markup = pd.read_csv('test_markup.csv', encoding='utf-16', header=None, names=NAMES)\n",
    "\n",
    "for idx in range(len(res)):\n",
    "    item = res[idx].numpy()\n",
    "    print(item)\n",
    "    out = 0\n",
    "    for i, val in enumerate(reversed(item[0])):\n",
    "        out += val * 10 ** i\n",
    "\n",
    "    test_markup.loc[idx, 'code'] = out\n",
    "    \n",
    "test_markup.to_csv('answer.csv', encoding='utf-16', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
